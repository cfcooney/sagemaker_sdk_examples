{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and run a hyperparameter tuning job with the SageMaker SDK and HuggingFace container\n",
    "1. Load data to S3 for training.\n",
    "2. Configure SageMaker HuggingFace estimator.\n",
    "3. Select hyperparameters to search.\n",
    "4. Configure hyperparameter sweep with SageMaker Tuner.\n",
    "5. Evaluate results.\n",
    "6. Use best model for inference and deploy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pip installs\n",
    "sagemaker, transformers, and datasets - versions can vary depending on needs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install \"sagemaker>=2.48.0\" \"transformers==4.12.3\" \"datasets[s3]==1.18.3\" --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "import sagemaker.huggingface\n",
    "from sagemaker.tuner import (\n",
    "    IntegerParameter,\n",
    "    CategoricalParameter,\n",
    "    ContinuousParameter,\n",
    "    HyperparameterTuner\n",
    ")\n",
    "\n",
    "from sagemaker.huggingface import HuggingFace\n",
    "\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "import s3fs\n",
    "\n",
    "from utils import summarize_hpo_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "session = sagemaker.Session()\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "role_name = role.split('/')[-1]\n",
    "\n",
    "sagemaker_session_bucket = session.default_bucket()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker role arn: arn:aws:iam::264639154954:role/aaca-ani-cogsci-sagemaker-studio-role\n",
      "sagemaker bucket: sagemaker-us-east-1-264639154954\n",
      "sagemaker session region: us-east-1\n"
     ]
    }
   ],
   "source": [
    "session = sagemaker.Session(default_bucket=sagemaker_session_bucket)\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {session.default_bucket()}\")\n",
    "print(f\"sagemaker session region: {session.boto_region_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download data from Datasets library and store in S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"imdb\"\n",
    "\n",
    "s3_prefix = \"samples/datasets/imdb\"\n",
    "\n",
    "tokenizer_name = \"distilbert-base-uncased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(dataset_name, ignore_verifications=True)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "\n",
    "#tokenizer helper function\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch['text'], padding='max_length', truncation=True)\n",
    "\n",
    "# load dataset\n",
    "train_dataset, test_dataset = load_dataset('imdb', split=['train', 'test'])\n",
    "test_dataset = test_dataset.shuffle().select(range(10000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.map(tokenize, batched=True, batch_size=len(train_dataset))\n",
    "test_dataset  = test_dataset.map(tokenize, batched=True, batch_size=len(test_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert to tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.rename_column(\"label\", \"labels\")\n",
    "train_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "test_dataset = test_dataset.rename_column(\"label\", \"labels\")\n",
    "test_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload data to S3 using the 'save_to_disk' Datasets method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-264639154954/samples/datasets/imdb/train\n",
      "s3://sagemaker-us-east-1-264639154954/samples/datasets/imdb/test\n"
     ]
    }
   ],
   "source": [
    "s3 = s3fs.S3FileSystem()\n",
    "\n",
    "training_input_path = f\"s3://{session.default_bucket()}/{s3_prefix}/train\"\n",
    "train_dataset.save_to_disk(training_input_path, fs=s3)\n",
    "\n",
    "test_input_path = f\"s3://{session.default_bucket()}/{s3_prefix}/test\"\n",
    "test_dataset.save_to_disk(test_input_path, fs=s3)\n",
    "\n",
    "print(f\"train_path: {training_input_path}\")\n",
    "print(f\"test_path: {test_input_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set hyperparamter values that are passed to the estimtor, but we are not seeking to tune."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hyperparameters = {\"epochs\": 1,\n",
    "                   \"train_batch_size\": 16,\n",
    "                   \"model_name\": \"distilbert-base-uncased\"\n",
    "                  }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure HuggingFace estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tags very useful in multi-user accounts for tracking key information\n",
    "TAGS = [{\"Key\": \"Owner\", \"Value\": \"ccooney@aflac.com\"},\n",
    "        {\"Key\": \"Environment\", \"Value\": \"Dev\"}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SageMaker has a specific estimator for use with HuggingFace (https://sagemaker.readthedocs.io/en/stable/frameworks/huggingface/sagemaker.huggingface.html)\n",
    "\n",
    "It requires a python script to be passed (this is the main training script for your model). Other important parameters include instance type and package versioning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "huggingface_estimator = HuggingFace(entry_point='training_script.py',\n",
    "                                    source_dir='./scripts',\n",
    "                                    sagemaker_session=session,\n",
    "                                    instance_type='ml.p3.2xlarge',\n",
    "                                    instance_count=1,\n",
    "                                    role=role,\n",
    "                                    transformers_version='4.12',\n",
    "                                    py_version='py38',\n",
    "                                    pytorch_version='1.9',\n",
    "                                    hyperparameters=hyperparameters,\n",
    "                                    base_job_name='hpo-HF')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize hyperparameter ranges and the metric for evaluating model performance.\n",
    "\n",
    "There are many hyperparameters that can be tuned the selection with largely be dependent on the type of model you are working with.\n",
    "\n",
    "The SageMaker SDK enables setting of hyperparameter ranges through the ContinuousParameter, IntegerParameter, and CategoricalParameter methods.\n",
    "\n",
    "Look at the arguments being parsed in training_script.py to see some other hyperparameters that could be tuned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hyperparameter_ranges = {\"learning_rate\": ContinuousParameter(0.0001, 0.1),\n",
    "                         \"warmup_steps\": IntegerParameter(100, 500),\n",
    "                         \"optimizer\": CategoricalParameter([\"AdamW\", \"Adafactor\"]),\n",
    "                         \"weight_decay\": ContinuousParameter(0.00, 0.001)}\n",
    "\n",
    "objective_metric = \"loss\"\n",
    "objective_type = \"Minimize\"\n",
    "metric_definitions = [{\"Name\": \"loss\", \"Regex\": \"loss = ([0-9\\\\.]+)\"}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure tuner\n",
    "Pass the estimator, as well as the objective metric and the hyperparameter ranges we want to tune.\n",
    "It is also possible to define the optimization strategy as 'Bayesian' | 'Random' | 'Hyperband' | 'Grid' (https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_HyperParameterTuningJobConfig.html) - Here, we go with the default Bayesian approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tuner = HyperparameterTuner(\n",
    "    huggingface_estimator,\n",
    "    objective_metric,\n",
    "    hyperparameter_ranges,\n",
    "    metric_definitions,\n",
    "    max_jobs=3,\n",
    "    max_parallel_jobs=1,\n",
    "    objective_type=objective_type,\n",
    "    tags=TAGS,\n",
    "    base_tuning_job_name=\"hpo-HF\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then call the fit method in the same way you would with a normal SageMaker estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..................................................................................................................................................................................................................................................................................................................................................................................................................................................................!\n"
     ]
    }
   ],
   "source": [
    "tuner.fit(inputs={\"train\": training_input_path, \"test\": test_input_path})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tuner.describe() prints details of the tuning job we created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'HyperParameterTuningJobName': 'huggingface-pytorch--230119-1050',\n",
       " 'HyperParameterTuningJobArn': 'arn:aws:sagemaker:us-east-1:264639154954:hyper-parameter-tuning-job/huggingface-pytorch--230119-1050',\n",
       " 'HyperParameterTuningJobConfig': {'Strategy': 'Bayesian',\n",
       "  'HyperParameterTuningJobObjective': {'Type': 'Minimize',\n",
       "   'MetricName': 'loss'},\n",
       "  'ResourceLimits': {'MaxNumberOfTrainingJobs': 3,\n",
       "   'MaxParallelTrainingJobs': 1},\n",
       "  'ParameterRanges': {'IntegerParameterRanges': [{'Name': 'warmup_steps',\n",
       "     'MinValue': '100',\n",
       "     'MaxValue': '500',\n",
       "     'ScalingType': 'Auto'}],\n",
       "   'ContinuousParameterRanges': [{'Name': 'learning_rate',\n",
       "     'MinValue': '0.0001',\n",
       "     'MaxValue': '0.1',\n",
       "     'ScalingType': 'Auto'}],\n",
       "   'CategoricalParameterRanges': []},\n",
       "  'TrainingJobEarlyStoppingType': 'Off'},\n",
       " 'TrainingJobDefinition': {'StaticHyperParameters': {'_tuning_objective_metric': 'loss',\n",
       "   'epochs': '1',\n",
       "   'model_name': '\"distilbert-base-uncased\"',\n",
       "   'sagemaker_container_log_level': '20',\n",
       "   'sagemaker_estimator_class_name': '\"HuggingFace\"',\n",
       "   'sagemaker_estimator_module': '\"sagemaker.huggingface.estimator\"',\n",
       "   'sagemaker_job_name': '\"hpo-HF-2023-01-19-10-50-51-248\"',\n",
       "   'sagemaker_program': '\"bespoke_training.py\"',\n",
       "   'sagemaker_region': '\"us-east-1\"',\n",
       "   'sagemaker_submit_directory': '\"s3://sagemaker-us-east-1-264639154954/hpo-HF-2023-01-19-10-50-51-248/source/sourcedir.tar.gz\"',\n",
       "   'train_batch_size': '16'},\n",
       "  'AlgorithmSpecification': {'TrainingImage': '763104351884.dkr.ecr.us-east-1.amazonaws.com/huggingface-pytorch-training:1.9-transformers4.12-gpu-py38-cu111-ubuntu20.04',\n",
       "   'TrainingInputMode': 'File',\n",
       "   'MetricDefinitions': [{'Name': 'loss', 'Regex': 'loss = ([0-9\\\\.]+)'},\n",
       "    {'Name': 'ObjectiveMetric', 'Regex': 'loss = ([0-9\\\\.]+)'}]},\n",
       "  'RoleArn': 'arn:aws:iam::264639154954:role/aaca-ani-cogsci-sagemaker-studio-role',\n",
       "  'InputDataConfig': [{'ChannelName': 'train',\n",
       "    'DataSource': {'S3DataSource': {'S3DataType': 'S3Prefix',\n",
       "      'S3Uri': 's3://sagemaker-us-east-1-264639154954/samples/datasets/imdb/train',\n",
       "      'S3DataDistributionType': 'FullyReplicated'}}},\n",
       "   {'ChannelName': 'test',\n",
       "    'DataSource': {'S3DataSource': {'S3DataType': 'S3Prefix',\n",
       "      'S3Uri': 's3://sagemaker-us-east-1-264639154954/samples/datasets/imdb/test',\n",
       "      'S3DataDistributionType': 'FullyReplicated'}}}],\n",
       "  'OutputDataConfig': {'S3OutputPath': 's3://sagemaker-us-east-1-264639154954/'},\n",
       "  'ResourceConfig': {'InstanceType': 'ml.p3.2xlarge',\n",
       "   'InstanceCount': 1,\n",
       "   'VolumeSizeInGB': 30},\n",
       "  'StoppingCondition': {'MaxRuntimeInSeconds': 86400},\n",
       "  'EnableNetworkIsolation': False,\n",
       "  'EnableInterContainerTrafficEncryption': False,\n",
       "  'EnableManagedSpotTraining': False},\n",
       " 'HyperParameterTuningJobStatus': 'Completed',\n",
       " 'CreationTime': datetime.datetime(2023, 1, 19, 10, 50, 51, 521000, tzinfo=tzlocal()),\n",
       " 'HyperParameterTuningEndTime': datetime.datetime(2023, 1, 19, 11, 28, 43, 855000, tzinfo=tzlocal()),\n",
       " 'LastModifiedTime': datetime.datetime(2023, 1, 19, 11, 28, 43, 855000, tzinfo=tzlocal()),\n",
       " 'TrainingJobStatusCounters': {'Completed': 3,\n",
       "  'InProgress': 0,\n",
       "  'RetryableError': 0,\n",
       "  'NonRetryableError': 0,\n",
       "  'Stopped': 0},\n",
       " 'ObjectiveStatusCounters': {'Succeeded': 3, 'Pending': 0, 'Failed': 0},\n",
       " 'BestTrainingJob': {'TrainingJobName': 'huggingface-pytorch--230119-1050-001-26fe4220',\n",
       "  'TrainingJobArn': 'arn:aws:sagemaker:us-east-1:264639154954:training-job/huggingface-pytorch--230119-1050-001-26fe4220',\n",
       "  'CreationTime': datetime.datetime(2023, 1, 19, 10, 50, 56, tzinfo=tzlocal()),\n",
       "  'TrainingStartTime': datetime.datetime(2023, 1, 19, 10, 52, 29, tzinfo=tzlocal()),\n",
       "  'TrainingEndTime': datetime.datetime(2023, 1, 19, 11, 6, 14, tzinfo=tzlocal()),\n",
       "  'TrainingJobStatus': 'Completed',\n",
       "  'TunedHyperParameters': {'learning_rate': '0.009935247403251076',\n",
       "   'warmup_steps': '339'},\n",
       "  'FinalHyperParameterTuningJobObjectiveMetric': {'MetricName': 'loss',\n",
       "   'Value': 0.006931567098945379},\n",
       "  'ObjectiveStatus': 'Succeeded'},\n",
       " 'ResponseMetadata': {'RequestId': 'b2be991d-e771-4026-b0fe-8f65920eaa07',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'b2be991d-e771-4026-b0fe-8f65920eaa07',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '3527',\n",
       "   'date': 'Thu, 19 Jan 2023 11:33:20 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuner.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the results as a pandas DataFrame for a comparison of all hyperparameter combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>warmup_steps</th>\n",
       "      <th>TrainingJobName</th>\n",
       "      <th>TrainingJobStatus</th>\n",
       "      <th>FinalObjectiveValue</th>\n",
       "      <th>TrainingStartTime</th>\n",
       "      <th>TrainingEndTime</th>\n",
       "      <th>TrainingElapsedTimeSeconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000767</td>\n",
       "      <td>459.0</td>\n",
       "      <td>huggingface-pytorch--230119-1050-003-5f576314</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.006932</td>\n",
       "      <td>2023-01-19 11:18:33+00:00</td>\n",
       "      <td>2023-01-19 11:27:48+00:00</td>\n",
       "      <td>555.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.018117</td>\n",
       "      <td>291.0</td>\n",
       "      <td>huggingface-pytorch--230119-1050-002-8a2cd885</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.006932</td>\n",
       "      <td>2023-01-19 11:08:17+00:00</td>\n",
       "      <td>2023-01-19 11:17:36+00:00</td>\n",
       "      <td>559.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.009935</td>\n",
       "      <td>339.0</td>\n",
       "      <td>huggingface-pytorch--230119-1050-001-26fe4220</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.006932</td>\n",
       "      <td>2023-01-19 10:52:29+00:00</td>\n",
       "      <td>2023-01-19 11:06:14+00:00</td>\n",
       "      <td>825.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   learning_rate  warmup_steps                                TrainingJobName  \\\n",
       "0       0.000767         459.0  huggingface-pytorch--230119-1050-003-5f576314   \n",
       "1       0.018117         291.0  huggingface-pytorch--230119-1050-002-8a2cd885   \n",
       "2       0.009935         339.0  huggingface-pytorch--230119-1050-001-26fe4220   \n",
       "\n",
       "  TrainingJobStatus  FinalObjectiveValue         TrainingStartTime  \\\n",
       "0         Completed             0.006932 2023-01-19 11:18:33+00:00   \n",
       "1         Completed             0.006932 2023-01-19 11:08:17+00:00   \n",
       "2         Completed             0.006932 2023-01-19 10:52:29+00:00   \n",
       "\n",
       "            TrainingEndTime  TrainingElapsedTimeSeconds  \n",
       "0 2023-01-19 11:27:48+00:00                       555.0  \n",
       "1 2023-01-19 11:17:36+00:00                       559.0  \n",
       "2 2023-01-19 11:06:14+00:00                       825.0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = tuner.analytics().dataframe()\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.sort_values('FinalObjectiveValue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print best results for ease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score: 0.006931567098945379\n",
      "best params: {'learning_rate': '0.009935247403251076', 'warmup_steps': '339'}\n",
      "best job-name: huggingface-pytorch--230119-1050-001-26fe4220\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'HyperParameterTuningJobName': 'huggingface-pytorch--230119-1050',\n",
       " 'HyperParameterTuningJobArn': 'arn:aws:sagemaker:us-east-1:264639154954:hyper-parameter-tuning-job/huggingface-pytorch--230119-1050',\n",
       " 'HyperParameterTuningJobConfig': {'Strategy': 'Bayesian',\n",
       "  'HyperParameterTuningJobObjective': {'Type': 'Minimize',\n",
       "   'MetricName': 'loss'},\n",
       "  'ResourceLimits': {'MaxNumberOfTrainingJobs': 3,\n",
       "   'MaxParallelTrainingJobs': 1},\n",
       "  'ParameterRanges': {'IntegerParameterRanges': [{'Name': 'warmup_steps',\n",
       "     'MinValue': '100',\n",
       "     'MaxValue': '500',\n",
       "     'ScalingType': 'Auto'}],\n",
       "   'ContinuousParameterRanges': [{'Name': 'learning_rate',\n",
       "     'MinValue': '0.0001',\n",
       "     'MaxValue': '0.1',\n",
       "     'ScalingType': 'Auto'}],\n",
       "   'CategoricalParameterRanges': []},\n",
       "  'TrainingJobEarlyStoppingType': 'Off'},\n",
       " 'TrainingJobDefinition': {'StaticHyperParameters': {'_tuning_objective_metric': 'loss',\n",
       "   'epochs': '1',\n",
       "   'model_name': '\"distilbert-base-uncased\"',\n",
       "   'sagemaker_container_log_level': '20',\n",
       "   'sagemaker_estimator_class_name': '\"HuggingFace\"',\n",
       "   'sagemaker_estimator_module': '\"sagemaker.huggingface.estimator\"',\n",
       "   'sagemaker_job_name': '\"hpo-HF-2023-01-19-10-50-51-248\"',\n",
       "   'sagemaker_program': '\"bespoke_training.py\"',\n",
       "   'sagemaker_region': '\"us-east-1\"',\n",
       "   'sagemaker_submit_directory': '\"s3://sagemaker-us-east-1-264639154954/hpo-HF-2023-01-19-10-50-51-248/source/sourcedir.tar.gz\"',\n",
       "   'train_batch_size': '16'},\n",
       "  'AlgorithmSpecification': {'TrainingImage': '763104351884.dkr.ecr.us-east-1.amazonaws.com/huggingface-pytorch-training:1.9-transformers4.12-gpu-py38-cu111-ubuntu20.04',\n",
       "   'TrainingInputMode': 'File',\n",
       "   'MetricDefinitions': [{'Name': 'loss', 'Regex': 'loss = ([0-9\\\\.]+)'},\n",
       "    {'Name': 'ObjectiveMetric', 'Regex': 'loss = ([0-9\\\\.]+)'}]},\n",
       "  'RoleArn': 'arn:aws:iam::264639154954:role/aaca-ani-cogsci-sagemaker-studio-role',\n",
       "  'InputDataConfig': [{'ChannelName': 'train',\n",
       "    'DataSource': {'S3DataSource': {'S3DataType': 'S3Prefix',\n",
       "      'S3Uri': 's3://sagemaker-us-east-1-264639154954/samples/datasets/imdb/train',\n",
       "      'S3DataDistributionType': 'FullyReplicated'}}},\n",
       "   {'ChannelName': 'test',\n",
       "    'DataSource': {'S3DataSource': {'S3DataType': 'S3Prefix',\n",
       "      'S3Uri': 's3://sagemaker-us-east-1-264639154954/samples/datasets/imdb/test',\n",
       "      'S3DataDistributionType': 'FullyReplicated'}}}],\n",
       "  'OutputDataConfig': {'S3OutputPath': 's3://sagemaker-us-east-1-264639154954/'},\n",
       "  'ResourceConfig': {'InstanceType': 'ml.p3.2xlarge',\n",
       "   'InstanceCount': 1,\n",
       "   'VolumeSizeInGB': 30},\n",
       "  'StoppingCondition': {'MaxRuntimeInSeconds': 86400},\n",
       "  'EnableNetworkIsolation': False,\n",
       "  'EnableInterContainerTrafficEncryption': False,\n",
       "  'EnableManagedSpotTraining': False},\n",
       " 'HyperParameterTuningJobStatus': 'Completed',\n",
       " 'CreationTime': datetime.datetime(2023, 1, 19, 10, 50, 51, 521000, tzinfo=tzlocal()),\n",
       " 'HyperParameterTuningEndTime': datetime.datetime(2023, 1, 19, 11, 28, 43, 855000, tzinfo=tzlocal()),\n",
       " 'LastModifiedTime': datetime.datetime(2023, 1, 19, 11, 28, 43, 855000, tzinfo=tzlocal()),\n",
       " 'TrainingJobStatusCounters': {'Completed': 3,\n",
       "  'InProgress': 0,\n",
       "  'RetryableError': 0,\n",
       "  'NonRetryableError': 0,\n",
       "  'Stopped': 0},\n",
       " 'ObjectiveStatusCounters': {'Succeeded': 3, 'Pending': 0, 'Failed': 0},\n",
       " 'BestTrainingJob': {'TrainingJobName': 'huggingface-pytorch--230119-1050-001-26fe4220',\n",
       "  'TrainingJobArn': 'arn:aws:sagemaker:us-east-1:264639154954:training-job/huggingface-pytorch--230119-1050-001-26fe4220',\n",
       "  'CreationTime': datetime.datetime(2023, 1, 19, 10, 50, 56, tzinfo=tzlocal()),\n",
       "  'TrainingStartTime': datetime.datetime(2023, 1, 19, 10, 52, 29, tzinfo=tzlocal()),\n",
       "  'TrainingEndTime': datetime.datetime(2023, 1, 19, 11, 6, 14, tzinfo=tzlocal()),\n",
       "  'TrainingJobStatus': 'Completed',\n",
       "  'TunedHyperParameters': {'learning_rate': '0.009935247403251076',\n",
       "   'warmup_steps': '339'},\n",
       "  'FinalHyperParameterTuningJobObjectiveMetric': {'MetricName': 'loss',\n",
       "   'Value': 0.006931567098945379},\n",
       "  'ObjectiveStatus': 'Succeeded'},\n",
       " 'ResponseMetadata': {'RequestId': '8919e699-3b49-4fa9-a269-aeb4d961e4cc',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '8919e699-3b49-4fa9-a269-aeb4d961e4cc',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '3527',\n",
       "   'date': 'Thu, 19 Jan 2023 11:39:32 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarize_hpo_results(tuner.latest_tuning_job.job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.best_training_job()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the best tuned model for deploying and making predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_estimator = tuner.best_estimator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deploy the model to a SageMaker Endpoint, choosing an instance type for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = huggingface_estimator.deploy(1, \"ml.g4dn.xlarge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use your deployed model to make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.predict({\"inputs\": \"I can say anything bad about this movie!\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete endpoint when complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.g4dn.xlarge",
  "interpreter": {
   "hash": "556bd3c69953d81d367d63bac13dd17e253d3fab989eb80647a7980e8f2979cc"
  },
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 1.8 Python 3.6 GPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/pytorch-1.8-gpu-py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
