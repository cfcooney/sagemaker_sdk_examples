{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1d37e21-689b-46c4-a11f-2d392acade69",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install \"sagemaker>=2.48.0\" \"transformers==4.12.3\" \"datasets[s3]==1.18.3\" --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16b2a702-dde3-417a-ba79-8b5f54e33920",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import os\n",
    "import sagemaker\n",
    "import json\n",
    "\n",
    "session = sagemaker.Session()\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "role_name = role.split('/')[-1]\n",
    "\n",
    "sagemaker_session_bucket = session.default_bucket()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "360248a5-5c24-4a00-b7cf-d78fc492fa8c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker role arn: arn:aws:iam::264639154954:role/aaca-ani-cogsci-sagemaker-studio-role\n",
      "sagemaker bucket: sagemaker-us-east-1-264639154954\n",
      "sagemaker session region: us-east-1\n"
     ]
    }
   ],
   "source": [
    "session = sagemaker.Session(default_bucket=sagemaker_session_bucket)\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {session.default_bucket()}\")\n",
    "print(f\"sagemaker session region: {session.boto_region_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d27158c2-107a-4984-aa5d-53faffd7a053",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-264639154954/samples/datasets/imdb/train\n",
      "s3://sagemaker-us-east-1-264639154954/samples/datasets/imdb/test\n"
     ]
    }
   ],
   "source": [
    "s3_prefix = \"samples/datasets/imdb\"\n",
    "\n",
    "training_input_path = f\"s3://{session.default_bucket()}/{s3_prefix}/train\"\n",
    "test_input_path = f\"s3://{session.default_bucket()}/{s3_prefix}/test\"\n",
    "\n",
    "print(training_input_path)\n",
    "print(test_input_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35d686b3-f243-4e1a-93bd-cf23bb43852f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.huggingface import HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02733cff-fad3-4d2f-b084-0b3884cd4d28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hyperparameters = {\"epochs\": 1,\n",
    "                   \"train_batch_size\": 16,\n",
    "                   \"model_name\": \"distilbert-base-uncased\"\n",
    "                  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96dd4b1a-a978-4d57-ad7c-ed93e451d683",
   "metadata": {},
   "outputs": [],
   "source": [
    "huggingface_estimator = HuggingFace(entry_point='bespoke_training.py',\n",
    "                                    source_dir='./scripts',\n",
    "                                    sagemaker_session=session,\n",
    "                                    instance_type='ml.p3.2xlarge',\n",
    "                                    instance_count=1,\n",
    "                                    role=role,\n",
    "                                    transformers_version='4.12',\n",
    "                                    py_version='py38',\n",
    "                                    pytorch_version='1.9',\n",
    "                                    hyperparameters=hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b62d3891-897a-4f41-9ad0-fc6964eb0937",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-16 08:50:58 Starting - Starting the training job...\n",
      "2023-01-16 08:51:24 Starting - Preparing the instances for trainingProfilerReport-1673859058: InProgress\n",
      "......\n",
      "2023-01-16 08:52:29 Downloading - Downloading input data...\n",
      "2023-01-16 08:52:50 Training - Downloading the training image........................\n",
      "2023-01-16 08:57:01 Training - Training image download completed. Training in progress.....\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2023-01-16 08:57:26,081 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2023-01-16 08:57:26,109 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2023-01-16 08:57:26,112 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2023-01-16 08:57:26,307 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python -m pip install -r requirements.txt\u001b[0m\n",
      "\u001b[34mCollecting evaluate\u001b[0m\n",
      "\u001b[34mDownloading evaluate-0.4.0-py3-none-any.whl (81 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 81.4/81.4 kB 15.8 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.8/site-packages (from evaluate->-r requirements.txt (line 1)) (2022.5.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: packaging in /opt/conda/lib/python3.8/site-packages (from evaluate->-r requirements.txt (line 1)) (21.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: multiprocess in /opt/conda/lib/python3.8/site-packages (from evaluate->-r requirements.txt (line 1)) (0.70.13)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: xxhash in /opt/conda/lib/python3.8/site-packages (from evaluate->-r requirements.txt (line 1)) (3.0.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.8/site-packages (from evaluate->-r requirements.txt (line 1)) (1.22.3)\u001b[0m\n",
      "\u001b[34mCollecting datasets>=2.0.0\u001b[0m\n",
      "\u001b[34mDownloading datasets-2.8.0-py3-none-any.whl (452 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 452.9/452.9 kB 59.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pandas in /opt/conda/lib/python3.8/site-packages (from evaluate->-r requirements.txt (line 1)) (1.2.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: dill in /opt/conda/lib/python3.8/site-packages (from evaluate->-r requirements.txt (line 1)) (0.3.5.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.8/site-packages (from evaluate->-r requirements.txt (line 1)) (0.7.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.8/site-packages (from evaluate->-r requirements.txt (line 1)) (4.64.0)\u001b[0m\n",
      "\u001b[34mCollecting responses<0.19\u001b[0m\n",
      "\u001b[34mDownloading responses-0.18.0-py3-none-any.whl (38 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.8/site-packages (from evaluate->-r requirements.txt (line 1)) (2.27.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: aiohttp in /opt/conda/lib/python3.8/site-packages (from datasets>=2.0.0->evaluate->-r requirements.txt (line 1)) (3.8.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.8/site-packages (from datasets>=2.0.0->evaluate->-r requirements.txt (line 1)) (5.4.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyarrow>=6.0.0 in /opt/conda/lib/python3.8/site-packages (from datasets>=2.0.0->evaluate->-r requirements.txt (line 1)) (6.0.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: filelock in /opt/conda/lib/python3.8/site-packages (from huggingface-hub>=0.7.0->evaluate->-r requirements.txt (line 1)) (3.7.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.8/site-packages (from huggingface-hub>=0.7.0->evaluate->-r requirements.txt (line 1)) (3.10.0.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyparsing<3,>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging->evaluate->-r requirements.txt (line 1)) (2.4.7)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests>=2.19.0->evaluate->-r requirements.txt (line 1)) (2022.5.18.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.8/site-packages (from requests>=2.19.0->evaluate->-r requirements.txt (line 1)) (2.0.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests>=2.19.0->evaluate->-r requirements.txt (line 1)) (1.26.6)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests>=2.19.0->evaluate->-r requirements.txt (line 1)) (2.10)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.8/site-packages (from pandas->evaluate->-r requirements.txt (line 1)) (2.8.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.8/site-packages (from pandas->evaluate->-r requirements.txt (line 1)) (2021.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas->evaluate->-r requirements.txt (line 1)) (1.16.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets>=2.0.0->evaluate->-r requirements.txt (line 1)) (21.4.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets>=2.0.0->evaluate->-r requirements.txt (line 1)) (6.0.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets>=2.0.0->evaluate->-r requirements.txt (line 1)) (4.0.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets>=2.0.0->evaluate->-r requirements.txt (line 1)) (1.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets>=2.0.0->evaluate->-r requirements.txt (line 1)) (1.3.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets>=2.0.0->evaluate->-r requirements.txt (line 1)) (1.7.2)\u001b[0m\n",
      "\u001b[34mInstalling collected packages: responses, datasets, evaluate\u001b[0m\n",
      "\u001b[34mAttempting uninstall: datasets\u001b[0m\n",
      "\u001b[34mFound existing installation: datasets 1.15.1\u001b[0m\n",
      "\u001b[34mUninstalling datasets-1.15.1:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled datasets-1.15.1\u001b[0m\n",
      "\u001b[34mSuccessfully installed datasets-2.8.0 evaluate-0.4.0 responses-0.18.0\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m[notice] A new release of pip available: 22.1.2 -> 22.3.1\u001b[0m\n",
      "\u001b[34m[notice] To update, run: pip install --upgrade pip\u001b[0m\n",
      "\u001b[34m2023-01-16 08:57:29,798 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2023-01-16 08:57:29,798 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2023-01-16 08:57:29,879 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"test\": \"/opt/ml/input/data/test\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"epochs\": 1,\n",
      "        \"model_name\": \"distilbert-base-uncased\",\n",
      "        \"train_batch_size\": 16\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"test\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"huggingface-pytorch-training-2023-01-16-08-50-58-042\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-264639154954/huggingface-pytorch-training-2023-01-16-08-50-58-042/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"bespoke_training\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.p3.2xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.p3.2xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"bespoke_training.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"epochs\":1,\"model_name\":\"distilbert-base-uncased\",\"train_batch_size\":16}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=bespoke_training.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p3.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.2xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"test\",\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=bespoke_training\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-264639154954/huggingface-pytorch-training-2023-01-16-08-50-58-042/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"epochs\":1,\"model_name\":\"distilbert-base-uncased\",\"train_batch_size\":16},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"huggingface-pytorch-training-2023-01-16-08-50-58-042\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-264639154954/huggingface-pytorch-training-2023-01-16-08-50-58-042/source/sourcedir.tar.gz\",\"module_name\":\"bespoke_training\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p3.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.2xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"bespoke_training.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--epochs\",\"1\",\"--model_name\",\"distilbert-base-uncased\",\"--train_batch_size\",\"16\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TEST=/opt/ml/input/data/test\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=1\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL_NAME=distilbert-base-uncased\u001b[0m\n",
      "\u001b[34mSM_HP_TRAIN_BATCH_SIZE=16\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python38.zip:/opt/conda/lib/python3.8:/opt/conda/lib/python3.8/lib-dynload:/opt/conda/lib/python3.8/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python bespoke_training.py --epochs 1 --model_name distilbert-base-uncased --train_batch_size 16\u001b[0m\n",
      "\u001b[34mDownloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading: 100%|██████████| 28.0/28.0 [00:00<00:00, 33.6kB/s]\u001b[0m\n",
      "\u001b[34mDownloading:   0%|          | 0.00/483 [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading: 100%|██████████| 483/483 [00:00<00:00, 651kB/s]\u001b[0m\n",
      "\u001b[34mDownloading:   0%|          | 0.00/226k [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading: 100%|██████████| 226k/226k [00:00<00:00, 54.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:   0%|          | 0.00/455k [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading: 100%|██████████| 455k/455k [00:00<00:00, 56.8MB/s]\u001b[0m\n",
      "\u001b[34m2023-01-16 08:57:32,211 - __main__ - INFO - Getting train dataloader\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.8/site-packages/datasets/arrow_dataset.py:1533: FutureWarning: 'fs' was is deprecated in favor of 'storage_options' in version 2.8.0 and will be removed in 3.0.0.\u001b[0m\n",
      "\u001b[34mYou can remove this warning by passing 'storage_options=fs.storage_options' instead.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m2023-01-16 08:57:32,217 - __main__ - INFO - Getting test dataloader.\u001b[0m\n",
      "\u001b[34mDownloading:   0%|          | 0.00/256M [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading:   3%|▎         | 6.54M/256M [00:00<00:03, 68.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:   5%|▌         | 13.7M/256M [00:00<00:03, 72.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:   8%|▊         | 21.2M/256M [00:00<00:03, 75.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  11%|█         | 28.7M/256M [00:00<00:03, 76.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  14%|█▍        | 36.2M/256M [00:00<00:02, 77.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  17%|█▋        | 43.7M/256M [00:00<00:02, 77.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  20%|██        | 51.2M/256M [00:00<00:02, 78.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  23%|██▎       | 58.8M/256M [00:00<00:02, 78.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  26%|██▌       | 66.4M/256M [00:00<00:02, 78.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  29%|██▉       | 74.0M/256M [00:01<00:02, 79.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  32%|███▏      | 81.5M/256M [00:01<00:02, 77.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  35%|███▍      | 89.1M/256M [00:01<00:02, 78.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  38%|███▊      | 96.6M/256M [00:01<00:02, 78.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  41%|████      | 104M/256M [00:01<00:02, 78.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  44%|████▎     | 112M/256M [00:01<00:01, 78.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  47%|████▋     | 119M/256M [00:01<00:01, 79.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  50%|████▉     | 127M/256M [00:01<00:01, 79.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  53%|█████▎    | 134M/256M [00:01<00:01, 79.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  56%|█████▌    | 142M/256M [00:01<00:01, 79.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  58%|█████▊    | 149M/256M [00:02<00:01, 79.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  61%|██████▏   | 157M/256M [00:02<00:01, 78.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  64%|██████▍   | 164M/256M [00:02<00:01, 78.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  67%|██████▋   | 172M/256M [00:02<00:01, 79.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  70%|███████   | 180M/256M [00:02<00:01, 78.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  73%|███████▎  | 187M/256M [00:02<00:00, 79.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  76%|███████▌  | 195M/256M [00:02<00:00, 79.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  79%|███████▉  | 202M/256M [00:02<00:00, 78.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  82%|████████▏ | 210M/256M [00:02<00:00, 79.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  85%|████████▌ | 217M/256M [00:02<00:00, 78.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  88%|████████▊ | 225M/256M [00:03<00:00, 79.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  91%|█████████ | 232M/256M [00:03<00:00, 78.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  94%|█████████▍| 240M/256M [00:03<00:00, 79.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  97%|█████████▋| 247M/256M [00:03<00:00, 78.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading: 100%|█████████▉| 255M/256M [00:03<00:00, 77.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading: 100%|██████████| 256M/256M [00:03<00:00, 78.3MB/s]\u001b[0m\n",
      "\u001b[34mSome weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_transform.bias', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_transform.weight']\u001b[0m\n",
      "\u001b[34m- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\u001b[0m\n",
      "\u001b[34m- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\u001b[0m\n",
      "\u001b[34mSome weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'pre_classifier.weight', 'classifier.bias', 'classifier.weight']\u001b[0m\n",
      "\u001b[34mYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001b[0m\n",
      "\u001b[34m0%|          | 0/1563 [00:00<?, ?batch/s]\u001b[0m\n",
      "\u001b[34m[2023-01-16 08:57:39.056 algo-1:35 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2023-01-16 08:57:39.146 algo-1:35 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[2023-01-16 08:57:39.146 algo-1:35 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2023-01-16 08:57:39.147 algo-1:35 INFO hook.py:200] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2023-01-16 08:57:39.147 algo-1:35 INFO hook.py:255] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2023-01-16 08:57:39.147 algo-1:35 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[2023-01-16 08:57:39.238 algo-1:35 INFO hook.py:591] name:distilbert.embeddings.word_embeddings.weight count_params:23440896\u001b[0m\n",
      "\u001b[34m[2023-01-16 08:57:39.238 algo-1:35 INFO hook.py:591] name:distilbert.embeddings.position_embeddings.weight count_params:393216\u001b[0m\n",
      "\u001b[34m[2023-01-16 08:57:39.238 algo-1:35 INFO hook.py:591] name:distilbert.embeddings.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2023-01-16 08:57:39.238 algo-1:35 INFO hook.py:591] name:distilbert.embeddings.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2023-01-16 08:57:39.238 algo-1:35 INFO hook.py:591] name:distilbert.transformer.layer.0.attention.q_lin.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2023-01-16 08:57:39.238 algo-1:35 INFO hook.py:591] name:distilbert.transformer.layer.0.attention.q_lin.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2023-01-16 08:57:39.238 algo-1:35 INFO hook.py:591] name:distilbert.transformer.layer.0.attention.k_lin.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2023-01-16 08:57:39.238 algo-1:35 INFO hook.py:591] name:distilbert.transformer.layer.0.attention.k_lin.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2023-01-16 08:57:39.238 algo-1:35 INFO hook.py:591] name:distilbert.transformer.layer.0.attention.v_lin.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2023-01-16 08:57:39.238 algo-1:35 INFO hook.py:591] name:distilbert.transformer.layer.0.attention.v_lin.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2023-01-16 08:57:39.238 algo-1:35 INFO hook.py:591] name:distilbert.transformer.layer.0.attention.out_lin.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2023-01-16 08:57:39.238 algo-1:35 INFO hook.py:591] name:distilbert.transformer.layer.0.attention.out_lin.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2023-01-16 08:57:39.239 algo-1:35 INFO hook.py:591] name:distilbert.transformer.layer.0.sa_layer_norm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2023-01-16 08:57:39.239 algo-1:35 INFO hook.py:591] name:distilbert.transformer.layer.0.sa_layer_norm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2023-01-16 08:57:39.239 algo-1:35 INFO hook.py:591] name:distilbert.transformer.layer.0.ffn.lin1.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2023-01-16 08:57:39.239 algo-1:35 INFO hook.py:591] name:distilbert.transformer.layer.0.ffn.lin1.bias count_params:3072\u001b[0m\n",
      "\u001b[34m[2023-01-16 08:57:39.239 algo-1:35 INFO hook.py:591] name:distilbert.transformer.layer.0.ffn.lin2.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2023-01-16 08:57:39.239 algo-1:35 INFO hook.py:591] name:distilbert.transformer.layer.0.ffn.lin2.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2023-01-16 08:57:39.239 algo-1:35 INFO hook.py:591] name:distilbert.transformer.layer.0.output_layer_norm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2023-01-16 08:57:39.239 algo-1:35 INFO hook.py:591] name:distilbert.transformer.layer.0.output_layer_norm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2023-01-16 08:57:39.239 algo-1:35 INFO hook.py:591] name:distilbert.transformer.layer.1.attention.q_lin.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2023-01-16 08:57:39.239 algo-1:35 INFO hook.py:591] name:distilbert.transformer.layer.1.attention.q_lin.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2023-01-16 08:57:39.239 algo-1:35 INFO hook.py:591] name:distilbert.transformer.layer.1.attention.k_lin.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2023-01-16 08:57:39.239 algo-1:35 INFO hook.py:591] name:distilbert.transformer.layer.1.attention.k_lin.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2023-01-16 08:57:39.239 algo-1:35 INFO hook.py:591] name:distilbert.transformer.layer.1.attention.v_lin.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2023-01-16 08:57:39.239 algo-1:35 INFO hook.py:591] name:distilbert.transformer.layer.1.attention.v_lin.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2023-01-16 08:57:39.240 algo-1:35 INFO hook.py:591] name:distilbert.transformer.layer.1.attention.out_lin.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2023-01-16 08:57:39.240 algo-1:35 INFO hook.py:591] name:distilbert.transformer.layer.1.attention.out_lin.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2023-01-16 08:57:39.240 algo-1:35 INFO hook.py:591] name:distilbert.transformer.layer.1.sa_layer_norm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2023-01-16 08:57:39.240 algo-1:35 INFO hook.py:591] name:distilbert.transformer.layer.1.sa_layer_norm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2023-01-16 08:57:39.240 algo-1:35 INFO hook.py:591] name:distilbert.transformer.layer.1.ffn.lin1.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2023-01-16 08:57:39.240 algo-1:35 INFO hook.py:591] name:distilbert.transformer.layer.1.ffn.lin1.bias count_params:3072\u001b[0m\n",
      "\u001b[34m[2023-01-16 08:57:39.240 algo-1:35 INFO hook.py:591] name:distilbert.transformer.layer.1.ffn.lin2.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2023-01-16 08:57:39.240 algo-1:35 INFO hook.py:591] name:distilbert.transformer.layer.1.ffn.lin2.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2023-01-16 08:57:39.240 algo-1:35 INFO hook.py:591] name:distilbert.transformer.layer.1.output_layer_norm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2023-01-16 08:57:39.240 algo-1:35 INFO hook.py:591] name:distilbert.transformer.layer.1.output_layer_norm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2023-01-16 08:57:39.240 algo-1:35 INFO hook.py:591] name:distilbert.transformer.layer.2.attention.q_lin.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2023-01-16 08:57:39.240 algo-1:35 INFO hook.py:591] name:distilbert.transformer.layer.2.attention.q_lin.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2023-01-16 08:57:39.240 algo-1:35 INFO hook.py:591] name:distilbert.transformer.layer.2.attention.k_lin.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2023-01-16 08:57:39.240 algo-1:35 INFO hook.py:591] name:distilbert.transformer.layer.2.attention.k_lin.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2023-01-16 08:57:39.240 algo-1:35 INFO hook.py:591] name:distilbert.transformer.layer.2.attention.v_lin.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2023-01-16 08:57:39.241 algo-1:35 INFO hook.py:591] name:distilbert.transformer.layer.2.attention.v_lin.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2023-01-16 08:57:39.241 algo-1:35 INFO hook.py:591] name:distilbert.transformer.layer.2.attention.out_lin.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2023-01-16 08:57:39.241 algo-1:35 INFO hook.py:591] name:distilbert.transformer.layer.2.attention.out_lin.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2023-01-16 08:57:39.241 algo-1:35 INFO hook.py:591] name:distilbert.transformer.layer.2.sa_layer_norm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2023-01-16 08:57:39.241 algo-1:35 INFO hook.py:591] name:distilbert.transformer.layer.2.sa_layer_norm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2023-01-16 08:57:39.241 algo-1:35 INFO hook.py:591] name:distilbert.transformer.layer.2.ffn.lin1.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2023-01-16 08:57:39.241 algo-1:35 INFO hook.py:591] name:distilbert.transformer.layer.2.ffn.lin1.bias count_params:3072\u001b[0m\n",
      "\u001b[34m[2023-01-16 08:57:39.241 algo-1:35 INFO hook.py:591] name:distilbert.transformer.layer.2.ffn.lin2.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2023-01-16 08:57:39.241 algo-1:35 INFO hook.py:591] name:distilbert.transformer.layer.2.ffn.lin2.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2023-01-16 08:57:39.241 algo-1:35 INFO hook.py:591] name:distilbert.transformer.layer.2.output_layer_norm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2023-01-16 08:57:39.241 algo-1:35 INFO hook.py:591] name:distilbert.transformer.layer.2.output_layer_norm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2023-01-16 08:57:39.241 algo-1:35 INFO hook.py:591] name:distilbert.transformer.layer.3.attention.q_lin.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2023-01-16 08:57:39.241 algo-1:35 INFO hook.py:591] name:distilbert.transformer.layer.3.attention.q_lin.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2023-01-16 08:57:39.241 algo-1:35 INFO hook.py:591] name:distilbert.transformer.layer.3.attention.k_lin.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2023-01-16 08:57:39.241 algo-1:35 INFO hook.py:591] name:distilbert.transformer.layer.3.attention.k_lin.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2023-01-16 08:57:39.242 algo-1:35 INFO hook.py:591] name:distilbert.transformer.layer.3.attention.v_lin.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2023-01-16 08:57:39.242 algo-1:35 INFO hook.py:591] name:distilbert.transformer.layer.3.attention.v_lin.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2023-01-16 08:57:39.242 algo-1:35 INFO hook.py:591] name:distilbert.transformer.layer.3.attention.out_lin.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2023-01-16 08:57:39.242 algo-1:35 INFO hook.py:591] name:distilbert.transformer.layer.3.attention.out_lin.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2023-01-16 08:57:39.242 algo-1:35 INFO hook.py:591] name:distilbert.transformer.layer.3.sa_layer_norm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2023-01-16 08:57:39.242 algo-1:35 INFO hook.py:591] name:distilbert.transformer.layer.3.sa_layer_norm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2023-01-16 08:57:39.242 algo-1:35 INFO hook.py:591] name:distilbert.transformer.layer.3.ffn.lin1.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2023-01-16 08:57:39.242 algo-1:35 INFO hook.py:591] name:distilbert.transformer.layer.3.ffn.lin1.bias count_params:3072\u001b[0m\n",
      "\u001b[34m[2023-01-16 08:57:39.242 algo-1:35 INFO hook.py:591] name:distilbert.transformer.layer.3.ffn.lin2.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2023-01-16 08:57:39.242 algo-1:35 INFO hook.py:591] name:distilbert.transformer.layer.3.ffn.lin2.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2023-01-16 08:57:39.242 algo-1:35 INFO hook.py:591] name:distilbert.transformer.layer.3.output_layer_norm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2023-01-16 08:57:39.242 algo-1:35 INFO hook.py:591] name:distilbert.transformer.layer.3.output_layer_norm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2023-01-16 08:57:39.242 algo-1:35 INFO hook.py:591] name:distilbert.transformer.layer.4.attention.q_lin.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2023-01-16 08:57:39.242 algo-1:35 INFO hook.py:591] name:distilbert.transformer.layer.4.attention.q_lin.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2023-01-16 08:57:39.242 algo-1:35 INFO hook.py:591] name:distilbert.transformer.layer.4.attention.k_lin.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2023-01-16 08:57:39.242 algo-1:35 INFO hook.py:591] name:distilbert.transformer.layer.4.attention.k_lin.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2023-01-16 08:57:39.243 algo-1:35 INFO hook.py:591] name:distilbert.transformer.layer.4.attention.v_lin.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2023-01-16 08:57:39.243 algo-1:35 INFO hook.py:591] name:distilbert.transformer.layer.4.attention.v_lin.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2023-01-16 08:57:39.243 algo-1:35 INFO hook.py:591] name:distilbert.transformer.layer.4.attention.out_lin.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2023-01-16 08:57:39.243 algo-1:35 INFO hook.py:591] name:distilbert.transformer.layer.4.attention.out_lin.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2023-01-16 08:57:39.243 algo-1:35 INFO hook.py:591] name:distilbert.transformer.layer.4.sa_layer_norm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2023-01-16 08:57:39.243 algo-1:35 INFO hook.py:591] name:distilbert.transformer.layer.4.sa_layer_norm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2023-01-16 08:57:39.243 algo-1:35 INFO hook.py:591] name:distilbert.transformer.layer.4.ffn.lin1.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2023-01-16 08:57:39.243 algo-1:35 INFO hook.py:591] name:distilbert.transformer.layer.4.ffn.lin1.bias count_params:3072\u001b[0m\n",
      "\u001b[34m[2023-01-16 08:57:39.243 algo-1:35 INFO hook.py:591] name:distilbert.transformer.layer.4.ffn.lin2.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2023-01-16 08:57:39.243 algo-1:35 INFO hook.py:591] name:distilbert.transformer.layer.4.ffn.lin2.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2023-01-16 08:57:39.243 algo-1:35 INFO hook.py:591] name:distilbert.transformer.layer.4.output_layer_norm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2023-01-16 08:57:39.243 algo-1:35 INFO hook.py:591] name:distilbert.transformer.layer.4.output_layer_norm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2023-01-16 08:57:39.243 algo-1:35 INFO hook.py:591] name:distilbert.transformer.layer.5.attention.q_lin.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2023-01-16 08:57:39.243 algo-1:35 INFO hook.py:591] name:distilbert.transformer.layer.5.attention.q_lin.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2023-01-16 08:57:39.244 algo-1:35 INFO hook.py:591] name:distilbert.transformer.layer.5.attention.k_lin.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2023-01-16 08:57:39.244 algo-1:35 INFO hook.py:591] name:distilbert.transformer.layer.5.attention.k_lin.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2023-01-16 08:57:39.244 algo-1:35 INFO hook.py:591] name:distilbert.transformer.layer.5.attention.v_lin.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2023-01-16 08:57:39.244 algo-1:35 INFO hook.py:591] name:distilbert.transformer.layer.5.attention.v_lin.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2023-01-16 08:57:39.244 algo-1:35 INFO hook.py:591] name:distilbert.transformer.layer.5.attention.out_lin.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2023-01-16 08:57:39.244 algo-1:35 INFO hook.py:591] name:distilbert.transformer.layer.5.attention.out_lin.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2023-01-16 08:57:39.244 algo-1:35 INFO hook.py:591] name:distilbert.transformer.layer.5.sa_layer_norm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2023-01-16 08:57:39.244 algo-1:35 INFO hook.py:591] name:distilbert.transformer.layer.5.sa_layer_norm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2023-01-16 08:57:39.244 algo-1:35 INFO hook.py:591] name:distilbert.transformer.layer.5.ffn.lin1.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2023-01-16 08:57:39.244 algo-1:35 INFO hook.py:591] name:distilbert.transformer.layer.5.ffn.lin1.bias count_params:3072\u001b[0m\n",
      "\u001b[34m[2023-01-16 08:57:39.244 algo-1:35 INFO hook.py:591] name:distilbert.transformer.layer.5.ffn.lin2.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2023-01-16 08:57:39.244 algo-1:35 INFO hook.py:591] name:distilbert.transformer.layer.5.ffn.lin2.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2023-01-16 08:57:39.244 algo-1:35 INFO hook.py:591] name:distilbert.transformer.layer.5.output_layer_norm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2023-01-16 08:57:39.244 algo-1:35 INFO hook.py:591] name:distilbert.transformer.layer.5.output_layer_norm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2023-01-16 08:57:39.245 algo-1:35 INFO hook.py:591] name:pre_classifier.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2023-01-16 08:57:39.245 algo-1:35 INFO hook.py:591] name:pre_classifier.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2023-01-16 08:57:39.245 algo-1:35 INFO hook.py:591] name:classifier.weight count_params:1536\u001b[0m\n",
      "\u001b[34m[2023-01-16 08:57:39.245 algo-1:35 INFO hook.py:591] name:classifier.bias count_params:2\u001b[0m\n",
      "\u001b[34m[2023-01-16 08:57:39.245 algo-1:35 INFO hook.py:593] Total Trainable Params: 66955010\u001b[0m\n",
      "\u001b[34m[2023-01-16 08:57:39.245 algo-1:35 INFO hook.py:424] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34m[2023-01-16 08:57:39.247 algo-1:35 INFO hook.py:488] Hook is writing from the hook with pid: 35\u001b[0m\n",
      "\u001b[34m0%|          | 0/1563 [00:01<?, ?batch/s, accuracy=50, loss=0.7]\u001b[0m\n",
      "\u001b[34m0%|          | 1/1563 [00:01<30:27,  1.17s/batch, accuracy=50, loss=0.7]\u001b[0m\n",
      "\u001b[34m0%|          | 1/1563 [00:01<30:27,  1.17s/batch, accuracy=43.8, loss=0.716]\u001b[0m\n",
      "\u001b[34m0%|          | 2/1563 [00:01<16:19,  1.59batch/s, accuracy=43.8, loss=0.716]\u001b[0m\n",
      "\u001b[34m0%|          | 2/1563 [00:01<16:19,  1.59batch/s, accuracy=50, loss=0.7]\u001b[0m\n",
      "\u001b[34m0%|          | 3/1563 [00:01<11:44,  2.21batch/s, accuracy=50, loss=0.7]\u001b[0m\n",
      "\u001b[34m0%|          | 3/1563 [00:01<11:44,  2.21batch/s, accuracy=31.2, loss=0.726]\u001b[0m\n",
      "\u001b[34m0%|          | 4/1563 [00:01<09:35,  2.71batch/s, accuracy=31.2, loss=0.726]\u001b[0m\n",
      "\u001b[34m0%|          | 4/1563 [00:02<09:35,  2.71batch/s, accuracy=56.2, loss=0.689]\u001b[0m\n",
      "\u001b[34m0%|          | 5/1563 [00:02<08:24,  3.09batch/s, accuracy=56.2, loss=0.689]\u001b[0m\n",
      "\u001b[34m0%|          | 5/1563 [00:02<08:24,  3.09batch/s, accuracy=68.8, loss=0.664]\u001b[0m\n",
      "\u001b[34m0%|          | 6/1563 [00:02<07:41,  3.37batch/s, accuracy=68.8, loss=0.664]\u001b[0m\n",
      "\u001b[34m0%|          | 6/1563 [00:02<07:41,  3.37batch/s, accuracy=37.5, loss=0.697]\u001b[0m\n",
      "\u001b[34m0%|          | 7/1563 [00:02<07:13,  3.59batch/s, accuracy=37.5, loss=0.697]\u001b[0m\n",
      "\u001b[34m0%|          | 7/1563 [00:02<07:13,  3.59batch/s, accuracy=50, loss=0.685]\u001b[0m\n",
      "\u001b[34m1%|          | 8/1563 [00:02<06:55,  3.74batch/s, accuracy=50, loss=0.685]\u001b[0m\n",
      "\u001b[34m1%|          | 8/1563 [00:03<06:55,  3.74batch/s, accuracy=68.8, loss=0.673]\u001b[0m\n",
      "\u001b[34m1%|          | 9/1563 [00:03<06:43,  3.85batch/s, accuracy=68.8, loss=0.673]\u001b[0m\n",
      "\u001b[34m1%|          | 9/1563 [00:03<06:43,  3.85batch/s, accuracy=50, loss=0.692]\u001b[0m\n",
      "\u001b[34m1%|          | 10/1563 [00:03<06:34,  3.93batch/s, accuracy=50, loss=0.692]\u001b[0m\n",
      "\u001b[34m1%|          | 10/1563 [00:03<06:34,  3.93batch/s, accuracy=56.2, loss=0.688]\u001b[0m\n",
      "\u001b[34m1%|          | 11/1563 [00:03<06:28,  3.99batch/s, accuracy=56.2, loss=0.688]\u001b[0m\n",
      "\u001b[34m1%|          | 11/1563 [00:03<06:28,  3.99batch/s, accuracy=56.2, loss=0.692]\u001b[0m\n",
      "\u001b[34m1%|          | 12/1563 [00:03<06:25,  4.03batch/s, accuracy=56.2, loss=0.692]\u001b[0m\n",
      "\u001b[34m1%|          | 12/1563 [00:04<06:25,  4.03batch/s, accuracy=50, loss=0.69]\u001b[0m\n",
      "\u001b[34m1%|          | 13/1563 [00:04<06:22,  4.05batch/s, accuracy=50, loss=0.69]\u001b[0m\n",
      "\u001b[34m1%|          | 13/1563 [00:04<06:22,  4.05batch/s, accuracy=50, loss=0.702]\u001b[0m\n",
      "\u001b[34m1%|          | 14/1563 [00:04<06:20,  4.07batch/s, accuracy=50, loss=0.702]\u001b[0m\n",
      "\u001b[34m1%|          | 14/1563 [00:04<06:20,  4.07batch/s, accuracy=62.5, loss=0.69]\u001b[0m\n",
      "\u001b[34m1%|          | 15/1563 [00:04<06:19,  4.08batch/s, accuracy=62.5, loss=0.69]\u001b[0m\n",
      "\u001b[34m1%|          | 15/1563 [00:04<06:19,  4.08batch/s, accuracy=68.8, loss=0.676]\u001b[0m\n",
      "\u001b[34m1%|          | 16/1563 [00:04<06:18,  4.09batch/s, accuracy=68.8, loss=0.676]\u001b[0m\n",
      "\u001b[34m1%|          | 16/1563 [00:05<06:18,  4.09batch/s, accuracy=50, loss=0.701]\u001b[0m\n",
      "\u001b[34m1%|          | 17/1563 [00:05<06:17,  4.09batch/s, accuracy=50, loss=0.701]\u001b[0m\n",
      "\u001b[34m1%|          | 17/1563 [00:05<06:17,  4.09batch/s, accuracy=37.5, loss=0.699]\u001b[0m\n",
      "\u001b[34m1%|          | 18/1563 [00:05<06:17,  4.09batch/s, accuracy=37.5, loss=0.699]\u001b[0m\n",
      "\u001b[34m1%|          | 18/1563 [00:05<06:17,  4.09batch/s, accuracy=25, loss=0.743]\u001b[0m\n",
      "\u001b[34m1%|          | 19/1563 [00:05<06:16,  4.10batch/s, accuracy=25, loss=0.743]\u001b[0m\n",
      "\u001b[34m1%|          | 19/1563 [00:05<06:16,  4.10batch/s, accuracy=43.8, loss=0.708]\u001b[0m\n",
      "\u001b[34m1%|▏         | 20/1563 [00:05<06:16,  4.10batch/s, accuracy=43.8, loss=0.708]\u001b[0m\n",
      "\u001b[34m1%|▏         | 20/1563 [00:06<06:16,  4.10batch/s, accuracy=62.5, loss=0.676]\u001b[0m\n",
      "\u001b[34m1%|▏         | 21/1563 [00:06<06:15,  4.11batch/s, accuracy=62.5, loss=0.676]\u001b[0m\n",
      "\u001b[34m1%|▏         | 21/1563 [00:06<06:15,  4.11batch/s, accuracy=37.5, loss=0.69]\u001b[0m\n",
      "\u001b[34m1%|▏         | 22/1563 [00:06<06:14,  4.11batch/s, accuracy=37.5, loss=0.69]\u001b[0m\n",
      "\u001b[34m1%|▏         | 22/1563 [00:06<06:14,  4.11batch/s, accuracy=56.2, loss=0.683]\u001b[0m\n",
      "\u001b[34m1%|▏         | 23/1563 [00:06<06:14,  4.12batch/s, accuracy=56.2, loss=0.683]\u001b[0m\n",
      "\u001b[34m1%|▏         | 23/1563 [00:06<06:14,  4.12batch/s, accuracy=56.2, loss=0.678]\u001b[0m\n",
      "\u001b[34m2%|▏         | 24/1563 [00:06<06:13,  4.12batch/s, accuracy=56.2, loss=0.678]\u001b[0m\n",
      "\u001b[34m2%|▏         | 24/1563 [00:07<06:13,  4.12batch/s, accuracy=37.5, loss=0.699]\u001b[0m\n",
      "\u001b[34m2%|▏         | 25/1563 [00:07<06:13,  4.12batch/s, accuracy=37.5, loss=0.699]\u001b[0m\n",
      "\u001b[34m2%|▏         | 25/1563 [00:07<06:13,  4.12batch/s, accuracy=50, loss=0.698]\u001b[0m\n",
      "\u001b[34m2%|▏         | 26/1563 [00:07<06:12,  4.12batch/s, accuracy=50, loss=0.698]\u001b[0m\n",
      "\u001b[34m2%|▏         | 26/1563 [00:07<06:12,  4.12batch/s, accuracy=56.2, loss=0.688]\u001b[0m\n",
      "\u001b[34m2%|▏         | 27/1563 [00:07<06:12,  4.12batch/s, accuracy=56.2, loss=0.688]\u001b[0m\n",
      "\u001b[34m2%|▏         | 27/1563 [00:07<06:12,  4.12batch/s, accuracy=56.2, loss=0.689]\u001b[0m\n",
      "\u001b[34m2%|▏         | 28/1563 [00:07<06:12,  4.12batch/s, accuracy=56.2, loss=0.689]\u001b[0m\n",
      "\u001b[34m2%|▏         | 28/1563 [00:07<06:12,  4.12batch/s, accuracy=56.2, loss=0.685]\u001b[0m\n",
      "\u001b[34m2%|▏         | 29/1563 [00:07<06:12,  4.12batch/s, accuracy=56.2, loss=0.685]\u001b[0m\n",
      "\u001b[34m2%|▏         | 29/1563 [00:08<06:12,  4.12batch/s, accuracy=43.8, loss=0.705]\u001b[0m\n",
      "\u001b[34m2%|▏         | 30/1563 [00:08<06:12,  4.12batch/s, accuracy=43.8, loss=0.705]\u001b[0m\n",
      "\u001b[34m2%|▏         | 30/1563 [00:08<06:12,  4.12batch/s, accuracy=37.5, loss=0.7]\u001b[0m\n",
      "\u001b[34m2%|▏         | 31/1563 [00:08<06:11,  4.12batch/s, accuracy=37.5, loss=0.7]\u001b[0m\n",
      "\u001b[34m2%|▏         | 31/1563 [00:08<06:11,  4.12batch/s, accuracy=43.8, loss=0.708]\u001b[0m\n",
      "\u001b[34m2%|▏         | 32/1563 [00:08<06:11,  4.12batch/s, accuracy=43.8, loss=0.708]\u001b[0m\n",
      "\u001b[34m2%|▏         | 32/1563 [00:08<06:11,  4.12batch/s, accuracy=37.5, loss=0.708]\u001b[0m\n",
      "\u001b[34m2%|▏         | 33/1563 [00:08<06:10,  4.13batch/s, accuracy=37.5, loss=0.708]\u001b[0m\n",
      "\u001b[34m2%|▏         | 33/1563 [00:09<06:10,  4.13batch/s, accuracy=68.8, loss=0.684]\u001b[0m\n",
      "\u001b[34m2%|▏         | 34/1563 [00:09<06:10,  4.13batch/s, accuracy=68.8, loss=0.684]\u001b[0m\n",
      "\u001b[34m2%|▏         | 34/1563 [00:09<06:10,  4.13batch/s, accuracy=50, loss=0.692]\u001b[0m\n",
      "\u001b[34m2%|▏         | 35/1563 [00:09<06:10,  4.13batch/s, accuracy=50, loss=0.692]\u001b[0m\n",
      "\u001b[34m2%|▏         | 35/1563 [00:09<06:10,  4.13batch/s, accuracy=62.5, loss=0.676]\u001b[0m\n",
      "\u001b[34m2%|▏         | 36/1563 [00:09<06:10,  4.13batch/s, accuracy=62.5, loss=0.676]\u001b[0m\n",
      "\u001b[34m2%|▏         | 36/1563 [00:09<06:10,  4.13batch/s, accuracy=25, loss=0.708]\u001b[0m\n",
      "\u001b[34m2%|▏         | 37/1563 [00:09<06:10,  4.12batch/s, accuracy=25, loss=0.708]\u001b[0m\n",
      "\u001b[34m2%|▏         | 37/1563 [00:10<06:10,  4.12batch/s, accuracy=56.2, loss=0.707]\u001b[0m\n",
      "\u001b[34m2%|▏         | 38/1563 [00:10<06:10,  4.11batch/s, accuracy=56.2, loss=0.707]\u001b[0m\n",
      "\u001b[34m2%|▏         | 38/1563 [00:10<06:10,  4.11batch/s, accuracy=43.8, loss=0.695]\u001b[0m\n",
      "\u001b[34m2%|▏         | 39/1563 [00:10<06:10,  4.11batch/s, accuracy=43.8, loss=0.695]\u001b[0m\n",
      "\u001b[34m2%|▏         | 39/1563 [00:10<06:10,  4.11batch/s, accuracy=50, loss=0.697]\u001b[0m\n",
      "\u001b[34m3%|▎         | 40/1563 [00:10<06:10,  4.11batch/s, accuracy=50, loss=0.697]\u001b[0m\n",
      "\u001b[34m3%|▎         | 40/1563 [00:10<06:10,  4.11batch/s, accuracy=56.2, loss=0.698]\u001b[0m\n",
      "\u001b[34m3%|▎         | 41/1563 [00:10<06:09,  4.12batch/s, accuracy=56.2, loss=0.698]\u001b[0m\n",
      "\u001b[34m3%|▎         | 41/1563 [00:11<06:09,  4.12batch/s, accuracy=50, loss=0.702]\u001b[0m\n",
      "\u001b[34m3%|▎         | 42/1563 [00:11<06:09,  4.12batch/s, accuracy=50, loss=0.702]\u001b[0m\n",
      "\u001b[34m3%|▎         | 42/1563 [00:11<06:09,  4.12batch/s, accuracy=50, loss=0.682]\u001b[0m\n",
      "\u001b[34m3%|▎         | 43/1563 [00:11<06:09,  4.12batch/s, accuracy=50, loss=0.682]\u001b[0m\n",
      "\u001b[34m3%|▎         | 43/1563 [00:11<06:09,  4.12batch/s, accuracy=62.5, loss=0.685]\u001b[0m\n",
      "\u001b[34m3%|▎         | 44/1563 [00:11<06:08,  4.12batch/s, accuracy=62.5, loss=0.685]\u001b[0m\n",
      "\u001b[34m3%|▎         | 44/1563 [00:11<06:08,  4.12batch/s, accuracy=68.8, loss=0.68]\u001b[0m\n",
      "\u001b[34m3%|▎         | 45/1563 [00:11<06:08,  4.12batch/s, accuracy=68.8, loss=0.68]\u001b[0m\n",
      "\u001b[34m3%|▎         | 45/1563 [00:12<06:08,  4.12batch/s, accuracy=81.2, loss=0.661]\u001b[0m\n",
      "\u001b[34m3%|▎         | 46/1563 [00:12<06:07,  4.12batch/s, accuracy=81.2, loss=0.661]\u001b[0m\n",
      "\u001b[34m3%|▎         | 46/1563 [00:12<06:07,  4.12batch/s, accuracy=75, loss=0.672]\u001b[0m\n",
      "\u001b[34m3%|▎         | 47/1563 [00:12<06:07,  4.12batch/s, accuracy=75, loss=0.672]\u001b[0m\n",
      "\u001b[34m3%|▎         | 47/1563 [00:12<06:07,  4.12batch/s, accuracy=43.8, loss=0.693]\u001b[0m\n",
      "\u001b[34m3%|▎         | 48/1563 [00:12<06:07,  4.13batch/s, accuracy=43.8, loss=0.693]\u001b[0m\n",
      "\u001b[34m3%|▎         | 48/1563 [00:12<06:07,  4.13batch/s, accuracy=68.8, loss=0.679]\u001b[0m\n",
      "\u001b[34m3%|▎         | 49/1563 [00:12<06:07,  4.12batch/s, accuracy=68.8, loss=0.679]\u001b[0m\n",
      "\u001b[34m3%|▎         | 49/1563 [00:13<06:07,  4.12batch/s, accuracy=81.2, loss=0.663]\u001b[0m\n",
      "\u001b[34m3%|▎         | 50/1563 [00:13<06:06,  4.12batch/s, accuracy=81.2, loss=0.663]\u001b[0m\n",
      "\u001b[34m3%|▎         | 50/1563 [00:13<06:06,  4.12batch/s, accuracy=43.8, loss=0.699]\u001b[0m\n",
      "\u001b[34m3%|▎         | 51/1563 [00:13<06:06,  4.13batch/s, accuracy=43.8, loss=0.699]\u001b[0m\n",
      "\u001b[34m3%|▎         | 51/1563 [00:13<06:06,  4.13batch/s, accuracy=31.2, loss=0.712]\u001b[0m\n",
      "\u001b[34m3%|▎         | 52/1563 [00:13<06:06,  4.13batch/s, accuracy=31.2, loss=0.712]\u001b[0m\n",
      "\u001b[34m3%|▎         | 52/1563 [00:13<06:06,  4.13batch/s, accuracy=56.2, loss=0.69]\u001b[0m\n",
      "\u001b[34m3%|▎         | 53/1563 [00:13<06:05,  4.13batch/s, accuracy=56.2, loss=0.69]\u001b[0m\n",
      "\u001b[34m3%|▎         | 53/1563 [00:14<06:05,  4.13batch/s, accuracy=62.5, loss=0.68]\u001b[0m\n",
      "\u001b[34m3%|▎         | 54/1563 [00:14<06:05,  4.13batch/s, accuracy=62.5, loss=0.68]\u001b[0m\n",
      "\u001b[34m3%|▎         | 54/1563 [00:14<06:05,  4.13batch/s, accuracy=37.5, loss=0.708]\u001b[0m\n",
      "\u001b[34m4%|▎         | 55/1563 [00:14<06:05,  4.12batch/s, accuracy=37.5, loss=0.708]\u001b[0m\n",
      "\u001b[34m4%|▎         | 55/1563 [00:14<06:05,  4.12batch/s, accuracy=68.8, loss=0.674]\u001b[0m\n",
      "\u001b[34m4%|▎         | 56/1563 [00:14<06:05,  4.12batch/s, accuracy=68.8, loss=0.674]\u001b[0m\n",
      "\u001b[34m4%|▎         | 56/1563 [00:14<06:05,  4.12batch/s, accuracy=75, loss=0.676]\u001b[0m\n",
      "\u001b[34m4%|▎         | 57/1563 [00:14<06:05,  4.13batch/s, accuracy=75, loss=0.676]\u001b[0m\n",
      "\u001b[34m4%|▎         | 57/1563 [00:15<06:05,  4.13batch/s, accuracy=50, loss=0.684]\u001b[0m\n",
      "\u001b[34m4%|▎         | 58/1563 [00:15<06:04,  4.12batch/s, accuracy=50, loss=0.684]\u001b[0m\n",
      "\u001b[34m4%|▎         | 58/1563 [00:15<06:04,  4.12batch/s, accuracy=50, loss=0.678]\u001b[0m\n",
      "\u001b[34m4%|▍         | 59/1563 [00:15<06:04,  4.12batch/s, accuracy=50, loss=0.678]\u001b[0m\n",
      "\u001b[34m4%|▍         | 59/1563 [00:15<06:04,  4.12batch/s, accuracy=68.8, loss=0.683]\u001b[0m\n",
      "\u001b[34m4%|▍         | 60/1563 [00:15<06:04,  4.12batch/s, accuracy=68.8, loss=0.683]\u001b[0m\n",
      "\u001b[34m4%|▍         | 60/1563 [00:15<06:04,  4.12batch/s, accuracy=81.2, loss=0.673]\u001b[0m\n",
      "\u001b[34m4%|▍         | 61/1563 [00:15<06:04,  4.12batch/s, accuracy=81.2, loss=0.673]\u001b[0m\n",
      "\u001b[34m4%|▍         | 61/1563 [00:15<06:04,  4.12batch/s, accuracy=75, loss=0.668]\u001b[0m\n",
      "\u001b[34m4%|▍         | 62/1563 [00:15<06:03,  4.13batch/s, accuracy=75, loss=0.668]\u001b[0m\n",
      "\u001b[34m4%|▍         | 62/1563 [00:16<06:03,  4.13batch/s, accuracy=68.8, loss=0.675]\u001b[0m\n",
      "\u001b[34m4%|▍         | 63/1563 [00:16<06:03,  4.13batch/s, accuracy=68.8, loss=0.675]\u001b[0m\n",
      "\u001b[34m4%|▍         | 63/1563 [00:16<06:03,  4.13batch/s, accuracy=68.8, loss=0.669]\u001b[0m\n",
      "\u001b[34m4%|▍         | 64/1563 [00:16<06:03,  4.13batch/s, accuracy=68.8, loss=0.669]\u001b[0m\n",
      "\u001b[34m4%|▍         | 64/1563 [00:16<06:03,  4.13batch/s, accuracy=68.8, loss=0.669]\u001b[0m\n",
      "\u001b[34m4%|▍         | 65/1563 [00:16<06:03,  4.13batch/s, accuracy=68.8, loss=0.669]\u001b[0m\n",
      "\u001b[34m4%|▍         | 65/1563 [00:16<06:03,  4.13batch/s, accuracy=81.2, loss=0.655]\u001b[0m\n",
      "\u001b[34m4%|▍         | 66/1563 [00:16<06:02,  4.12batch/s, accuracy=81.2, loss=0.655]\u001b[0m\n",
      "\u001b[34m4%|▍         | 66/1563 [00:17<06:02,  4.12batch/s, accuracy=75, loss=0.661]\u001b[0m\n",
      "\u001b[34m4%|▍         | 67/1563 [00:17<06:02,  4.12batch/s, accuracy=75, loss=0.661]\u001b[0m\n",
      "\u001b[34m4%|▍         | 67/1563 [00:17<06:02,  4.12batch/s, accuracy=56.2, loss=0.688]\u001b[0m\n",
      "\u001b[34m4%|▍         | 68/1563 [00:17<06:02,  4.12batch/s, accuracy=56.2, loss=0.688]\u001b[0m\n",
      "\u001b[34m4%|▍         | 68/1563 [00:17<06:02,  4.12batch/s, accuracy=68.8, loss=0.666]\u001b[0m\n",
      "\u001b[34m4%|▍         | 69/1563 [00:17<06:02,  4.13batch/s, accuracy=68.8, loss=0.666]\u001b[0m\n",
      "\u001b[34m4%|▍         | 69/1563 [00:17<06:02,  4.13batch/s, accuracy=56.2, loss=0.693]\u001b[0m\n",
      "\u001b[34m4%|▍         | 70/1563 [00:17<06:02,  4.12batch/s, accuracy=56.2, loss=0.693]\u001b[0m\n",
      "\u001b[34m4%|▍         | 70/1563 [00:18<06:02,  4.12batch/s, accuracy=68.8, loss=0.674]\u001b[0m\n",
      "\u001b[34m5%|▍         | 71/1563 [00:18<06:01,  4.12batch/s, accuracy=68.8, loss=0.674]\u001b[0m\n",
      "\u001b[34m5%|▍         | 71/1563 [00:18<06:01,  4.12batch/s, accuracy=75, loss=0.664]\u001b[0m\n",
      "\u001b[34m5%|▍         | 72/1563 [00:18<06:01,  4.13batch/s, accuracy=75, loss=0.664]\u001b[0m\n",
      "\u001b[34m5%|▍         | 72/1563 [00:18<06:01,  4.13batch/s, accuracy=75, loss=0.658]\u001b[0m\n",
      "\u001b[34m5%|▍         | 73/1563 [00:18<06:01,  4.13batch/s, accuracy=75, loss=0.658]\u001b[0m\n",
      "\u001b[34m5%|▍         | 73/1563 [00:18<06:01,  4.13batch/s, accuracy=62.5, loss=0.675]\u001b[0m\n",
      "\u001b[34m5%|▍         | 74/1563 [00:18<06:00,  4.13batch/s, accuracy=62.5, loss=0.675]\u001b[0m\n",
      "\u001b[34m5%|▍         | 74/1563 [00:19<06:00,  4.13batch/s, accuracy=81.2, loss=0.66]\u001b[0m\n",
      "\u001b[34m5%|▍         | 75/1563 [00:19<06:00,  4.13batch/s, accuracy=81.2, loss=0.66]\u001b[0m\n",
      "\u001b[34m5%|▍         | 75/1563 [00:19<06:00,  4.13batch/s, accuracy=62.5, loss=0.665]\u001b[0m\n",
      "\u001b[34m5%|▍         | 76/1563 [00:19<06:00,  4.13batch/s, accuracy=62.5, loss=0.665]\u001b[0m\n",
      "\u001b[34m5%|▍         | 76/1563 [00:19<06:00,  4.13batch/s, accuracy=68.8, loss=0.664]\u001b[0m\n",
      "\u001b[34m5%|▍         | 77/1563 [00:19<05:59,  4.13batch/s, accuracy=68.8, loss=0.664]\u001b[0m\n",
      "\u001b[34m5%|▍         | 77/1563 [00:19<05:59,  4.13batch/s, accuracy=56.2, loss=0.676]\u001b[0m\n",
      "\u001b[34m5%|▍         | 78/1563 [00:19<05:59,  4.13batch/s, accuracy=56.2, loss=0.676]\u001b[0m\n",
      "\u001b[34m5%|▍         | 78/1563 [00:20<05:59,  4.13batch/s, accuracy=81.2, loss=0.64]\u001b[0m\n",
      "\u001b[34m5%|▌         | 79/1563 [00:20<06:00,  4.12batch/s, accuracy=81.2, loss=0.64]\u001b[0m\n",
      "\u001b[34m5%|▌         | 79/1563 [00:20<06:00,  4.12batch/s, accuracy=75, loss=0.656]\u001b[0m\n",
      "\u001b[34m5%|▌         | 80/1563 [00:20<05:59,  4.12batch/s, accuracy=75, loss=0.656]\u001b[0m\n",
      "\u001b[34m5%|▌         | 80/1563 [00:20<05:59,  4.12batch/s, accuracy=81.2, loss=0.621]\u001b[0m\n",
      "\u001b[34m5%|▌         | 81/1563 [00:20<05:59,  4.13batch/s, accuracy=81.2, loss=0.621]\u001b[0m\n",
      "\u001b[34m5%|▌         | 81/1563 [00:20<05:59,  4.13batch/s, accuracy=62.5, loss=0.669]\u001b[0m\n",
      "\u001b[34m5%|▌         | 82/1563 [00:20<05:58,  4.13batch/s, accuracy=62.5, loss=0.669]\u001b[0m\n",
      "\u001b[34m5%|▌         | 82/1563 [00:21<05:58,  4.13batch/s, accuracy=87.5, loss=0.635]\u001b[0m\n",
      "\u001b[34m5%|▌         | 83/1563 [00:21<05:58,  4.12batch/s, accuracy=87.5, loss=0.635]\u001b[0m\n",
      "\u001b[34m5%|▌         | 83/1563 [00:21<05:58,  4.12batch/s, accuracy=81.2, loss=0.603]\u001b[0m\n",
      "\u001b[34m5%|▌         | 84/1563 [00:21<05:58,  4.12batch/s, accuracy=81.2, loss=0.603]\u001b[0m\n",
      "\u001b[34m5%|▌         | 84/1563 [00:21<05:58,  4.12batch/s, accuracy=75, loss=0.635]\u001b[0m\n",
      "\u001b[34m5%|▌         | 85/1563 [00:21<05:58,  4.12batch/s, accuracy=75, loss=0.635]\u001b[0m\n",
      "\u001b[34m5%|▌         | 85/1563 [00:21<05:58,  4.12batch/s, accuracy=68.8, loss=0.653]\u001b[0m\n",
      "\u001b[34m6%|▌         | 86/1563 [00:21<05:58,  4.13batch/s, accuracy=68.8, loss=0.653]\u001b[0m\n",
      "\u001b[34m6%|▌         | 86/1563 [00:22<05:58,  4.13batch/s, accuracy=62.5, loss=0.656]\u001b[0m\n",
      "\u001b[34m6%|▌         | 87/1563 [00:22<05:58,  4.12batch/s, accuracy=62.5, loss=0.656]\u001b[0m\n",
      "\u001b[34m6%|▌         | 87/1563 [00:22<05:58,  4.12batch/s, accuracy=56.2, loss=0.663]\u001b[0m\n",
      "\u001b[34m6%|▌         | 88/1563 [00:22<05:58,  4.12batch/s, accuracy=56.2, loss=0.663]\u001b[0m\n",
      "\u001b[34m6%|▌         | 88/1563 [00:22<05:58,  4.12batch/s, accuracy=87.5, loss=0.582]\u001b[0m\n",
      "\u001b[34m6%|▌         | 89/1563 [00:22<05:57,  4.12batch/s, accuracy=87.5, loss=0.582]\u001b[0m\n",
      "\u001b[34m6%|▌         | 89/1563 [00:22<05:57,  4.12batch/s, accuracy=68.8, loss=0.644]\u001b[0m\n",
      "\u001b[34m6%|▌         | 90/1563 [00:22<05:57,  4.12batch/s, accuracy=68.8, loss=0.644]\u001b[0m\n",
      "\u001b[34m6%|▌         | 90/1563 [00:23<05:57,  4.12batch/s, accuracy=87.5, loss=0.588]\u001b[0m\n",
      "\u001b[34m6%|▌         | 91/1563 [00:23<05:57,  4.12batch/s, accuracy=87.5, loss=0.588]\u001b[0m\n",
      "\u001b[34m6%|▌         | 91/1563 [00:23<05:57,  4.12batch/s, accuracy=87.5, loss=0.595]\u001b[0m\n",
      "\u001b[34m6%|▌         | 92/1563 [00:23<05:57,  4.11batch/s, accuracy=87.5, loss=0.595]\u001b[0m\n",
      "\u001b[34m6%|▌         | 92/1563 [00:23<05:57,  4.11batch/s, accuracy=62.5, loss=0.676]\u001b[0m\n",
      "\u001b[34m6%|▌         | 93/1563 [00:23<05:57,  4.11batch/s, accuracy=62.5, loss=0.676]\u001b[0m\n",
      "\u001b[34m6%|▌         | 93/1563 [00:23<05:57,  4.11batch/s, accuracy=68.8, loss=0.611]\u001b[0m\n",
      "\u001b[34m6%|▌         | 94/1563 [00:23<05:58,  4.10batch/s, accuracy=68.8, loss=0.611]\u001b[0m\n",
      "\u001b[34m6%|▌         | 94/1563 [00:23<05:58,  4.10batch/s, accuracy=68.8, loss=0.605]\u001b[0m\n",
      "\u001b[34m6%|▌         | 95/1563 [00:23<05:58,  4.09batch/s, accuracy=68.8, loss=0.605]\u001b[0m\n",
      "\u001b[34m6%|▌         | 95/1563 [00:24<05:58,  4.09batch/s, accuracy=75, loss=0.597]\u001b[0m\n",
      "\u001b[34m6%|▌         | 96/1563 [00:24<05:58,  4.10batch/s, accuracy=75, loss=0.597]\u001b[0m\n",
      "\u001b[34m6%|▌         | 96/1563 [00:24<05:58,  4.10batch/s, accuracy=68.8, loss=0.608]\u001b[0m\n",
      "\u001b[34m6%|▌         | 97/1563 [00:24<05:58,  4.09batch/s, accuracy=68.8, loss=0.608]\u001b[0m\n",
      "\u001b[34m6%|▌         | 97/1563 [00:24<05:58,  4.09batch/s, accuracy=87.5, loss=0.534]\u001b[0m\n",
      "\u001b[34m6%|▋         | 98/1563 [00:24<05:57,  4.09batch/s, accuracy=87.5, loss=0.534]\u001b[0m\n",
      "\u001b[34m6%|▋         | 98/1563 [00:24<05:57,  4.09batch/s, accuracy=93.8, loss=0.52]\u001b[0m\n",
      "\u001b[34m6%|▋         | 99/1563 [00:24<05:57,  4.10batch/s, accuracy=93.8, loss=0.52]\u001b[0m\n",
      "\u001b[34m6%|▋         | 99/1563 [00:25<05:57,  4.10batch/s, accuracy=75, loss=0.549]\u001b[0m\n",
      "\u001b[34m6%|▋         | 100/1563 [00:25<05:56,  4.11batch/s, accuracy=75, loss=0.549]\u001b[0m\n",
      "\u001b[34m6%|▋         | 100/1563 [00:25<05:56,  4.11batch/s, accuracy=68.8, loss=0.553]\u001b[0m\n",
      "\u001b[34m6%|▋         | 101/1563 [00:25<05:55,  4.11batch/s, accuracy=68.8, loss=0.553]\u001b[0m\n",
      "\u001b[34m6%|▋         | 101/1563 [00:25<05:55,  4.11batch/s, accuracy=75, loss=0.618]\u001b[0m\n",
      "\u001b[34m7%|▋         | 102/1563 [00:25<05:55,  4.11batch/s, accuracy=75, loss=0.618]\u001b[0m\n",
      "\u001b[34m7%|▋         | 102/1563 [00:25<05:55,  4.11batch/s, accuracy=75, loss=0.49]\u001b[0m\n",
      "\u001b[34m7%|▋         | 103/1563 [00:25<05:54,  4.12batch/s, accuracy=75, loss=0.49]\u001b[0m\n",
      "\u001b[34m7%|▋         | 103/1563 [00:26<05:54,  4.12batch/s, accuracy=75, loss=0.525]\u001b[0m\n",
      "\u001b[34m7%|▋         | 104/1563 [00:26<05:54,  4.11batch/s, accuracy=75, loss=0.525]\u001b[0m\n",
      "\u001b[34m7%|▋         | 104/1563 [00:26<05:54,  4.11batch/s, accuracy=81.2, loss=0.498]\u001b[0m\n",
      "\u001b[34m7%|▋         | 105/1563 [00:26<05:54,  4.11batch/s, accuracy=81.2, loss=0.498]\u001b[0m\n",
      "\u001b[34m7%|▋         | 105/1563 [00:26<05:54,  4.11batch/s, accuracy=81.2, loss=0.516]\u001b[0m\n",
      "\u001b[34m7%|▋         | 106/1563 [00:26<05:53,  4.12batch/s, accuracy=81.2, loss=0.516]\u001b[0m\n",
      "\u001b[34m7%|▋         | 106/1563 [00:26<05:53,  4.12batch/s, accuracy=87.5, loss=0.497]\u001b[0m\n",
      "\u001b[34m7%|▋         | 107/1563 [00:26<05:53,  4.12batch/s, accuracy=87.5, loss=0.497]\u001b[0m\n",
      "\u001b[34m7%|▋         | 107/1563 [00:27<05:53,  4.12batch/s, accuracy=81.2, loss=0.482]\u001b[0m\n",
      "\u001b[34m7%|▋         | 108/1563 [00:27<05:53,  4.11batch/s, accuracy=81.2, loss=0.482]\u001b[0m\n",
      "\u001b[34m7%|▋         | 108/1563 [00:27<05:53,  4.11batch/s, accuracy=81.2, loss=0.426]\u001b[0m\n",
      "\u001b[34m7%|▋         | 109/1563 [00:27<05:53,  4.11batch/s, accuracy=81.2, loss=0.426]\u001b[0m\n",
      "\u001b[34m7%|▋         | 109/1563 [00:27<05:53,  4.11batch/s, accuracy=75, loss=0.542]\u001b[0m\n",
      "\u001b[34m7%|▋         | 110/1563 [00:27<05:54,  4.10batch/s, accuracy=75, loss=0.542]\u001b[0m\n",
      "\u001b[34m7%|▋         | 110/1563 [00:27<05:54,  4.10batch/s, accuracy=100, loss=0.353]\u001b[0m\n",
      "\u001b[34m7%|▋         | 111/1563 [00:27<05:54,  4.09batch/s, accuracy=100, loss=0.353]\u001b[0m\n",
      "\u001b[34m7%|▋         | 111/1563 [00:28<05:54,  4.09batch/s, accuracy=100, loss=0.322]\u001b[0m\n",
      "\u001b[34m7%|▋         | 112/1563 [00:28<05:55,  4.08batch/s, accuracy=100, loss=0.322]\u001b[0m\n",
      "\u001b[34m7%|▋         | 112/1563 [00:28<05:55,  4.08batch/s, accuracy=81.2, loss=0.483]\u001b[0m\n",
      "\u001b[34m7%|▋         | 113/1563 [00:28<05:54,  4.09batch/s, accuracy=81.2, loss=0.483]\u001b[0m\n",
      "\u001b[34m7%|▋         | 113/1563 [00:28<05:54,  4.09batch/s, accuracy=81.2, loss=0.446]\u001b[0m\n",
      "\u001b[34m7%|▋         | 114/1563 [00:28<05:54,  4.09batch/s, accuracy=81.2, loss=0.446]\u001b[0m\n",
      "\u001b[34m7%|▋         | 114/1563 [00:28<05:54,  4.09batch/s, accuracy=81.2, loss=0.464]\u001b[0m\n",
      "\u001b[34m7%|▋         | 115/1563 [00:28<05:53,  4.09batch/s, accuracy=81.2, loss=0.464]\u001b[0m\n",
      "\u001b[34m7%|▋         | 115/1563 [00:29<05:53,  4.09batch/s, accuracy=93.8, loss=0.311]\u001b[0m\n",
      "\u001b[34m7%|▋         | 116/1563 [00:29<05:54,  4.08batch/s, accuracy=93.8, loss=0.311]\u001b[0m\n",
      "\u001b[34m7%|▋         | 116/1563 [00:29<05:54,  4.08batch/s, accuracy=87.5, loss=0.406]\u001b[0m\n",
      "\u001b[34m7%|▋         | 117/1563 [00:29<05:53,  4.08batch/s, accuracy=87.5, loss=0.406]\u001b[0m\n",
      "\u001b[34m7%|▋         | 117/1563 [00:29<05:53,  4.08batch/s, accuracy=87.5, loss=0.348]\u001b[0m\n",
      "\u001b[34m8%|▊         | 118/1563 [00:29<05:52,  4.10batch/s, accuracy=87.5, loss=0.348]\u001b[0m\n",
      "\u001b[34m8%|▊         | 118/1563 [00:29<05:52,  4.10batch/s, accuracy=93.8, loss=0.294]\u001b[0m\n",
      "\u001b[34m8%|▊         | 119/1563 [00:29<05:52,  4.10batch/s, accuracy=93.8, loss=0.294]\u001b[0m\n",
      "\u001b[34m8%|▊         | 119/1563 [00:30<05:52,  4.10batch/s, accuracy=100, loss=0.219]\u001b[0m\n",
      "\u001b[34m8%|▊         | 120/1563 [00:30<05:51,  4.10batch/s, accuracy=100, loss=0.219]\u001b[0m\n",
      "\u001b[34m8%|▊         | 120/1563 [00:30<05:51,  4.10batch/s, accuracy=87.5, loss=0.389]\u001b[0m\n",
      "\u001b[34m8%|▊         | 121/1563 [00:30<05:51,  4.11batch/s, accuracy=87.5, loss=0.389]\u001b[0m\n",
      "\u001b[34m8%|▊         | 121/1563 [00:30<05:51,  4.11batch/s, accuracy=100, loss=0.156]\u001b[0m\n",
      "\u001b[34m8%|▊         | 122/1563 [00:30<05:50,  4.11batch/s, accuracy=100, loss=0.156]\u001b[0m\n",
      "\u001b[34m8%|▊         | 122/1563 [00:30<05:50,  4.11batch/s, accuracy=75, loss=0.454]\u001b[0m\n",
      "\u001b[34m8%|▊         | 123/1563 [00:30<05:50,  4.11batch/s, accuracy=75, loss=0.454]\u001b[0m\n",
      "\u001b[34m8%|▊         | 123/1563 [00:31<05:50,  4.11batch/s, accuracy=75, loss=0.509]\u001b[0m\n",
      "\u001b[34m8%|▊         | 124/1563 [00:31<05:50,  4.11batch/s, accuracy=75, loss=0.509]\u001b[0m\n",
      "\u001b[34m8%|▊         | 124/1563 [00:31<05:50,  4.11batch/s, accuracy=93.8, loss=0.24]\u001b[0m\n",
      "\u001b[34m8%|▊         | 125/1563 [00:31<05:49,  4.11batch/s, accuracy=93.8, loss=0.24]\u001b[0m\n",
      "\u001b[34m8%|▊         | 125/1563 [00:31<05:49,  4.11batch/s, accuracy=93.8, loss=0.282]\u001b[0m\n",
      "\u001b[34m8%|▊         | 126/1563 [00:31<05:49,  4.11batch/s, accuracy=93.8, loss=0.282]\u001b[0m\n",
      "\u001b[34m8%|▊         | 126/1563 [00:31<05:49,  4.11batch/s, accuracy=75, loss=0.406]\u001b[0m\n",
      "\u001b[34m8%|▊         | 127/1563 [00:31<05:49,  4.11batch/s, accuracy=75, loss=0.406]\u001b[0m\n",
      "\u001b[34m8%|▊         | 127/1563 [00:32<05:49,  4.11batch/s, accuracy=87.5, loss=0.318]\u001b[0m\n",
      "\u001b[34m8%|▊         | 128/1563 [00:32<05:49,  4.11batch/s, accuracy=87.5, loss=0.318]\u001b[0m\n",
      "\u001b[34m8%|▊         | 128/1563 [00:32<05:49,  4.11batch/s, accuracy=81.2, loss=0.445]\u001b[0m\n",
      "\u001b[34m8%|▊         | 129/1563 [00:32<05:48,  4.11batch/s, accuracy=81.2, loss=0.445]\u001b[0m\n",
      "\u001b[34m8%|▊         | 129/1563 [00:32<05:48,  4.11batch/s, accuracy=93.8, loss=0.188]\u001b[0m\n",
      "\u001b[34m8%|▊         | 130/1563 [00:32<05:48,  4.11batch/s, accuracy=93.8, loss=0.188]\u001b[0m\n",
      "\u001b[34m8%|▊         | 130/1563 [00:32<05:48,  4.11batch/s, accuracy=87.5, loss=0.227]\u001b[0m\n",
      "\u001b[34m8%|▊         | 131/1563 [00:32<05:48,  4.11batch/s, accuracy=87.5, loss=0.227]\u001b[0m\n",
      "\u001b[34m8%|▊         | 131/1563 [00:33<05:48,  4.11batch/s, accuracy=93.8, loss=0.234]\u001b[0m\n",
      "\u001b[34m8%|▊         | 132/1563 [00:33<05:47,  4.11batch/s, accuracy=93.8, loss=0.234]\u001b[0m\n",
      "\u001b[34m8%|▊         | 132/1563 [00:33<05:47,  4.11batch/s, accuracy=93.8, loss=0.176]\u001b[0m\n",
      "\u001b[34m9%|▊         | 133/1563 [00:33<05:47,  4.11batch/s, accuracy=93.8, loss=0.176]\u001b[0m\n",
      "\u001b[34m9%|▊         | 133/1563 [00:33<05:47,  4.11batch/s, accuracy=87.5, loss=0.342]\u001b[0m\n",
      "\u001b[34m9%|▊         | 134/1563 [00:33<05:47,  4.11batch/s, accuracy=87.5, loss=0.342]\u001b[0m\n",
      "\u001b[34m9%|▊         | 134/1563 [00:33<05:47,  4.11batch/s, accuracy=81.2, loss=0.368]\u001b[0m\n",
      "\u001b[34m9%|▊         | 135/1563 [00:33<05:47,  4.11batch/s, accuracy=81.2, loss=0.368]\u001b[0m\n",
      "\u001b[34m9%|▊         | 135/1563 [00:33<05:47,  4.11batch/s, accuracy=100, loss=0.165]\u001b[0m\n",
      "\u001b[34m9%|▊         | 136/1563 [00:33<05:46,  4.11batch/s, accuracy=100, loss=0.165]\u001b[0m\n",
      "\u001b[34m9%|▊         | 136/1563 [00:34<05:46,  4.11batch/s, accuracy=87.5, loss=0.288]\u001b[0m\n",
      "\u001b[34m9%|▉         | 137/1563 [00:34<05:46,  4.11batch/s, accuracy=87.5, loss=0.288]\u001b[0m\n",
      "\u001b[34m9%|▉         | 137/1563 [00:34<05:46,  4.11batch/s, accuracy=68.8, loss=0.644]\u001b[0m\n",
      "\u001b[34m9%|▉         | 138/1563 [00:34<05:46,  4.11batch/s, accuracy=68.8, loss=0.644]\u001b[0m\n",
      "\u001b[34m9%|▉         | 138/1563 [00:34<05:46,  4.11batch/s, accuracy=87.5, loss=0.305]\u001b[0m\n",
      "\u001b[34m9%|▉         | 139/1563 [00:34<05:46,  4.11batch/s, accuracy=87.5, loss=0.305]\u001b[0m\n",
      "\u001b[34m9%|▉         | 139/1563 [00:34<05:46,  4.11batch/s, accuracy=75, loss=0.454]\u001b[0m\n",
      "\u001b[34m9%|▉         | 140/1563 [00:34<05:45,  4.12batch/s, accuracy=75, loss=0.454]\u001b[0m\n",
      "\u001b[34m9%|▉         | 140/1563 [00:35<05:45,  4.12batch/s, accuracy=68.8, loss=0.783]\u001b[0m\n",
      "\u001b[34m9%|▉         | 141/1563 [00:35<05:45,  4.11batch/s, accuracy=68.8, loss=0.783]\u001b[0m\n",
      "\u001b[34m9%|▉         | 141/1563 [00:35<05:45,  4.11batch/s, accuracy=75, loss=0.46]\u001b[0m\n",
      "\u001b[34m9%|▉         | 142/1563 [00:35<05:45,  4.11batch/s, accuracy=75, loss=0.46]\u001b[0m\n",
      "\u001b[34m9%|▉         | 142/1563 [00:35<05:45,  4.11batch/s, accuracy=87.5, loss=0.356]\u001b[0m\n",
      "\u001b[34m9%|▉         | 143/1563 [00:35<05:45,  4.11batch/s, accuracy=87.5, loss=0.356]\u001b[0m\n",
      "\u001b[34m9%|▉         | 143/1563 [00:35<05:45,  4.11batch/s, accuracy=81.2, loss=0.411]\u001b[0m\n",
      "\u001b[34m9%|▉         | 144/1563 [00:35<05:45,  4.11batch/s, accuracy=81.2, loss=0.411]\u001b[0m\n",
      "\u001b[34m9%|▉         | 144/1563 [00:36<05:45,  4.11batch/s, accuracy=87.5, loss=0.281]\u001b[0m\n",
      "\u001b[34m9%|▉         | 145/1563 [00:36<05:45,  4.11batch/s, accuracy=87.5, loss=0.281]\u001b[0m\n",
      "\u001b[34m9%|▉         | 145/1563 [00:36<05:45,  4.11batch/s, accuracy=75, loss=0.379]\u001b[0m\n",
      "\u001b[34m9%|▉         | 146/1563 [00:36<05:44,  4.11batch/s, accuracy=75, loss=0.379]\u001b[0m\n",
      "\u001b[34m9%|▉         | 146/1563 [00:36<05:44,  4.11batch/s, accuracy=81.2, loss=0.422]\u001b[0m\n",
      "\u001b[34m9%|▉         | 147/1563 [00:36<05:44,  4.11batch/s, accuracy=81.2, loss=0.422]\u001b[0m\n",
      "\u001b[34m9%|▉         | 147/1563 [00:36<05:44,  4.11batch/s, accuracy=81.2, loss=0.321]\u001b[0m\n",
      "\u001b[34m9%|▉         | 148/1563 [00:36<05:44,  4.11batch/s, accuracy=81.2, loss=0.321]\u001b[0m\n",
      "\u001b[34m9%|▉         | 148/1563 [00:37<05:44,  4.11batch/s, accuracy=62.5, loss=0.551]\u001b[0m\n",
      "\u001b[34m10%|▉         | 149/1563 [00:37<05:43,  4.11batch/s, accuracy=62.5, loss=0.551]\u001b[0m\n",
      "\u001b[34m10%|▉         | 149/1563 [00:37<05:43,  4.11batch/s, accuracy=68.8, loss=0.655]\u001b[0m\n",
      "\u001b[34m10%|▉         | 150/1563 [00:37<05:43,  4.11batch/s, accuracy=68.8, loss=0.655]\u001b[0m\n",
      "\u001b[34m10%|▉         | 150/1563 [00:37<05:43,  4.11batch/s, accuracy=81.2, loss=0.494]\u001b[0m\n",
      "\u001b[34m10%|▉         | 151/1563 [00:37<05:43,  4.11batch/s, accuracy=81.2, loss=0.494]\u001b[0m\n",
      "\u001b[34m10%|▉         | 151/1563 [00:37<05:43,  4.11batch/s, accuracy=93.8, loss=0.245]\u001b[0m\n",
      "\u001b[34m10%|▉         | 152/1563 [00:37<05:43,  4.11batch/s, accuracy=93.8, loss=0.245]\u001b[0m\n",
      "\u001b[34m10%|▉         | 152/1563 [00:38<05:43,  4.11batch/s, accuracy=93.8, loss=0.219]\u001b[0m\n",
      "\u001b[34m10%|▉         | 153/1563 [00:38<05:42,  4.11batch/s, accuracy=93.8, loss=0.219]\u001b[0m\n",
      "\u001b[34m10%|▉         | 153/1563 [00:38<05:42,  4.11batch/s, accuracy=93.8, loss=0.3]\u001b[0m\n",
      "\u001b[34m10%|▉         | 154/1563 [00:38<05:42,  4.11batch/s, accuracy=93.8, loss=0.3]\u001b[0m\n",
      "\u001b[34m10%|▉         | 154/1563 [00:38<05:42,  4.11batch/s, accuracy=75, loss=0.456]\u001b[0m\n",
      "\u001b[34m10%|▉         | 155/1563 [00:38<05:42,  4.11batch/s, accuracy=75, loss=0.456]\u001b[0m\n",
      "\u001b[34m10%|▉         | 155/1563 [00:38<05:42,  4.11batch/s, accuracy=75, loss=0.479]\u001b[0m\n",
      "\u001b[34m10%|▉         | 156/1563 [00:38<05:42,  4.11batch/s, accuracy=75, loss=0.479]\u001b[0m\n",
      "\u001b[34m10%|▉         | 156/1563 [00:39<05:42,  4.11batch/s, accuracy=81.2, loss=0.505]\u001b[0m\n",
      "\u001b[34m10%|█         | 157/1563 [00:39<05:41,  4.11batch/s, accuracy=81.2, loss=0.505]\u001b[0m\n",
      "\u001b[34m10%|█         | 157/1563 [00:39<05:41,  4.11batch/s, accuracy=68.8, loss=0.569]\u001b[0m\n",
      "\u001b[34m10%|█         | 158/1563 [00:39<05:41,  4.11batch/s, accuracy=68.8, loss=0.569]\u001b[0m\n",
      "\u001b[34m10%|█         | 158/1563 [00:39<05:41,  4.11batch/s, accuracy=87.5, loss=0.378]\u001b[0m\n",
      "\u001b[34m10%|█         | 159/1563 [00:39<05:41,  4.11batch/s, accuracy=87.5, loss=0.378]\u001b[0m\n",
      "\u001b[34m10%|█         | 159/1563 [00:39<05:41,  4.11batch/s, accuracy=87.5, loss=0.229]\u001b[0m\n",
      "\u001b[34m10%|█         | 160/1563 [00:39<05:40,  4.11batch/s, accuracy=87.5, loss=0.229]\u001b[0m\n",
      "\u001b[34m10%|█         | 160/1563 [00:40<05:40,  4.11batch/s, accuracy=87.5, loss=0.404]\u001b[0m\n",
      "\u001b[34m10%|█         | 161/1563 [00:40<05:40,  4.12batch/s, accuracy=87.5, loss=0.404]\u001b[0m\n",
      "\u001b[34m10%|█         | 161/1563 [00:40<05:40,  4.12batch/s, accuracy=81.2, loss=0.481]\u001b[0m\n",
      "\u001b[34m10%|█         | 162/1563 [00:40<05:40,  4.12batch/s, accuracy=81.2, loss=0.481]\u001b[0m\n",
      "\u001b[34m10%|█         | 162/1563 [00:40<05:40,  4.12batch/s, accuracy=87.5, loss=0.411]\u001b[0m\n",
      "\u001b[34m10%|█         | 163/1563 [00:40<05:40,  4.11batch/s, accuracy=87.5, loss=0.411]\u001b[0m\n",
      "\u001b[34m10%|█         | 163/1563 [00:40<05:40,  4.11batch/s, accuracy=81.2, loss=0.341]\u001b[0m\n",
      "\u001b[34m10%|█         | 164/1563 [00:40<05:40,  4.11batch/s, accuracy=81.2, loss=0.341]\u001b[0m\n",
      "\u001b[34m10%|█         | 164/1563 [00:41<05:40,  4.11batch/s, accuracy=81.2, loss=0.348]\u001b[0m\n",
      "\u001b[34m11%|█         | 165/1563 [00:41<05:40,  4.11batch/s, accuracy=81.2, loss=0.348]\u001b[0m\n",
      "\u001b[34m11%|█         | 165/1563 [00:41<05:40,  4.11batch/s, accuracy=100, loss=0.216]\u001b[0m\n",
      "\u001b[34m11%|█         | 166/1563 [00:41<05:40,  4.10batch/s, accuracy=100, loss=0.216]\u001b[0m\n",
      "\u001b[34m11%|█         | 166/1563 [00:41<05:40,  4.10batch/s, accuracy=93.8, loss=0.182]\u001b[0m\n",
      "\u001b[34m11%|█         | 167/1563 [00:41<05:40,  4.10batch/s, accuracy=93.8, loss=0.182]\u001b[0m\n",
      "\u001b[34m11%|█         | 167/1563 [00:41<05:40,  4.10batch/s, accuracy=100, loss=0.139]\u001b[0m\n",
      "\u001b[34m11%|█         | 168/1563 [00:41<05:40,  4.10batch/s, accuracy=100, loss=0.139]\u001b[0m\n",
      "\u001b[34m11%|█         | 168/1563 [00:42<05:40,  4.10batch/s, accuracy=87.5, loss=0.251]\u001b[0m\n",
      "\u001b[34m11%|█         | 169/1563 [00:42<05:40,  4.10batch/s, accuracy=87.5, loss=0.251]\u001b[0m\n",
      "\u001b[34m11%|█         | 169/1563 [00:42<05:40,  4.10batch/s, accuracy=81.2, loss=0.434]\u001b[0m\n",
      "\u001b[34m11%|█         | 170/1563 [00:42<05:40,  4.10batch/s, accuracy=81.2, loss=0.434]\u001b[0m\n",
      "\u001b[34m11%|█         | 170/1563 [00:42<05:40,  4.10batch/s, accuracy=81.2, loss=0.31]\u001b[0m\n",
      "\u001b[34m11%|█         | 171/1563 [00:42<05:39,  4.10batch/s, accuracy=81.2, loss=0.31]\u001b[0m\n",
      "\u001b[34m11%|█         | 171/1563 [00:42<05:39,  4.10batch/s, accuracy=93.8, loss=0.281]\u001b[0m\n",
      "\u001b[34m11%|█         | 172/1563 [00:42<05:39,  4.10batch/s, accuracy=93.8, loss=0.281]\u001b[0m\n",
      "\u001b[34m11%|█         | 172/1563 [00:42<05:39,  4.10batch/s, accuracy=81.2, loss=0.498]\u001b[0m\n",
      "\u001b[34m11%|█         | 173/1563 [00:42<05:38,  4.10batch/s, accuracy=81.2, loss=0.498]\u001b[0m\n",
      "\u001b[34m11%|█         | 173/1563 [00:43<05:38,  4.10batch/s, accuracy=68.8, loss=0.546]\u001b[0m\n",
      "\u001b[34m11%|█         | 174/1563 [00:43<05:38,  4.11batch/s, accuracy=68.8, loss=0.546]\u001b[0m\n",
      "\u001b[34m11%|█         | 174/1563 [00:43<05:38,  4.11batch/s, accuracy=100, loss=0.16]\u001b[0m\n",
      "\u001b[34m11%|█         | 175/1563 [00:43<05:38,  4.10batch/s, accuracy=100, loss=0.16]\u001b[0m\n",
      "\u001b[34m11%|█         | 175/1563 [00:43<05:38,  4.10batch/s, accuracy=81.2, loss=0.553]\u001b[0m\n",
      "\u001b[34m11%|█▏        | 176/1563 [00:43<05:38,  4.10batch/s, accuracy=81.2, loss=0.553]\u001b[0m\n",
      "\u001b[34m11%|█▏        | 176/1563 [00:43<05:38,  4.10batch/s, accuracy=93.8, loss=0.155]\u001b[0m\n",
      "\u001b[34m11%|█▏        | 177/1563 [00:43<05:38,  4.10batch/s, accuracy=93.8, loss=0.155]\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-4064e6ac5f6b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhuggingface_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtraining_input_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"test\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtest_input_path\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sagemaker/workflow/pipeline_context.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    270\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_StepArguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretrieve_caller_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_instance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mrun_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, inputs, wait, logs, job_name, experiment_config)\u001b[0m\n\u001b[1;32m   1126\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1128\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_compilation_job_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m   2240\u001b[0m         \u001b[0;31m# If logs are requested, call logs_for_jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2241\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlogs\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"None\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2242\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogs_for_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2243\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2244\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mlogs_for_job\u001b[0;34m(self, job_name, wait, poll, log_type)\u001b[0m\n\u001b[1;32m   3841\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3842\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3843\u001b[0;31m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3844\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3845\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mLogState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mJOB_COMPLETE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "huggingface_estimator.fit({\"train\": training_input_path, \"test\": test_input_path})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e381875-a0f2-48bc-b068-a798bff9dc49",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Now deploy the model so that it can be used for inference\n",
    "There are a couple of easy ways to so this:\n",
    "1. Directly from the estimator itself.\n",
    "2. Using the HuggingFaceModel class to deploy a model stored in S3.\n",
    "\n",
    "## Deploy from estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "96d1d338-703a-4bde-ab2e-bdf8b897f67f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-264639154954/huggingface-pytorch-training-2023-01-13-17-26-31-869/output/model.tar.gz'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor = huggingface_estimator.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.m4.xlarge\",)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3389981f-0489-4d80-b7a0-2479e4a7c0e0",
   "metadata": {},
   "source": [
    "## Deploy from HuggingFaceModel class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a8ffa776-56fb-4447-be6b-2b9448e1b793",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.huggingface import HuggingFaceModel\n",
    "\n",
    "# create Hugging Face Model Class\n",
    "huggingface_model = HuggingFaceModel(\n",
    "   model_data=huggingface_estimator.model_data,  # path to your trained sagemaker model\n",
    "   role=role, # iam role with permissions to create an Endpoint\n",
    "   transformers_version='4.12', # transformers version used\n",
    "   pytorch_version=huggingface_estimator.pytorch_version, # pytorch version used\n",
    "   py_version=huggingface_estimator.py_version, # python version of the DLC\n",
    "   env={ 'HF_TASK':'text-classification' }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "54f32d29-c3f8-45bd-a46a-e64ae8a23517",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----!"
     ]
    }
   ],
   "source": [
    "predictor = huggingface_model.deploy(\n",
    "   initial_instance_count=1,\n",
    "   instance_type=\"ml.m4.xlarge\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab39d91-7140-4569-b7d0-557a550e95f7",
   "metadata": {},
   "source": [
    "## Test results by passing in a dict containing an \"inputs\" key and a text string.\n",
    "LABEL_0 == 'negative'\n",
    "LABEL_1 == 'positive'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4e82b5c8-f567-425b-abe1-c7b14b0854b7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_0', 'score': 0.9453563094139099}]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.predict({\"inputs\":\"i DID NOT LIKE THIS.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3d326729-1522-4b1d-9d51-cf1d5f2b9acf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = predictor.predict({\"inputs\":\"i DID NOT LIKE THIS.\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5b3187-6941-459b-8145-77a6ff09aa03",
   "metadata": {},
   "source": [
    "Convert predictor labels in to negative/positive classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a588fc4f-487b-4124-9945-832bb02c5c88",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LABEL_0': 'negative', 'LABEL_1': 'positive'}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = [\"negative\", \"positive\"]\n",
    "id2label = {f\"LABEL_{v}\": k for v, k in enumerate(classes)}\n",
    "id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a488b911-7984-44a2-a292-20f7fb6c143e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative\n"
     ]
    }
   ],
   "source": [
    "for result in results:\n",
    "    print(id2label[result['label']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305cf04d-58bf-4360-8a3a-844fa86ef931",
   "metadata": {
    "tags": []
   },
   "source": [
    "# We can also look at how the model performed against individual samples from the test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "465c2bf2-d9f5-4fa5-abdb-5b340945b0fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e561ef32-62f0-4ed8-ae8c-248ab2d40844",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d5f71aa8-dbbf-4d95-b8fa-d1a1e3b54310",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer_name = \"distilbert-base-uncased\"\n",
    "\n",
    "dataset_name = \"imdb\"\n",
    "\n",
    "s3_prefix = \"samples/datasets/imdb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5bdf2700-8d3c-4b6b-a44d-f02f1bc69e90",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset imdb (/root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9be7f455aab645d8bf28d3e9053a29bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset imdb (/root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efb3134a348b4ff8bb75d42dd2794144",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset(dataset_name, ignore_verifications=True)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "\n",
    "#tokenizer helper function\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch['text'], padding='max_length', truncation=True)\n",
    "\n",
    "# load dataset\n",
    "train_dataset, test_dataset = load_dataset('imdb', split=['train', 'test'])\n",
    "test_dataset = test_dataset.shuffle().select(range(10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d2fd9c29-ffda-480b-abf0-9dd6d02ccac6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a035dc2d38374591be25e025a6edaec6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_dataset  = test_dataset.map(tokenize, batched=True, batch_size=len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e7fea2e7-3808-4060-b465-148b9f3b59b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_dataset = test_dataset.rename_column(\"label\", \"labels\")\n",
    "test_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50116d04-23c0-4c66-83f7-d6e36f011b15",
   "metadata": {},
   "source": [
    "## Decode test set tokens using our tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f10345a5-367b-4a3c-a365-653aec88afd4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"one of the worse surfing movies i've ever seen. this movie is so bad i don't know where to begin - - okay, let's start with the premise - some dude from the mainland who barely knows how to surf travels to hawaii and enters a big wave contest which he more or less expects to win. a good analogy for those who don't surf would be a that of a grossly overweight chain smoker slapping on a pairs of running shoes and entering the la marathon with expectations of winning. no way! and, the contest is held on the north shore which conjures up images of 15 + foot waves, but contest day the waves are maybe 6 foot. the acting? what acting? if you must see this woof see it on tv, don't waste your money renting it. if you want to see a pretty good surfing movie - granted it is flawed, but that's another story - rent big wednesday.\""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(test_dataset[0]['input_ids'], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2caa562b-c545-4c6c-8c12-ac8c4daa8649",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "sample_mask = np.random.randint(0, 10_000, size=(10)).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "86fb4394-d3f5-4577-bb6c-04ef1420750a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 0, 0, 0, 1, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth = [test_dataset[i]['labels'].cpu().numpy().item() for i in sample_mask]\n",
    "ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "5bf5e7f7-3c25-4622-bad3-4ea92bf86ad0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'positive'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2label[f\"LABEL_{test_dataset[sample_mask[0]]['labels'].cpu().numpy().item()}\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190f24be-9e56-4150-b703-b338c632d9ca",
   "metadata": {},
   "source": [
    "## Pass the predictor a list of strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "aa2b2a13-9d8c-444b-ad82-fa4d4b48e53e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_1', 'score': 0.959917426109314},\n",
       " {'label': 'LABEL_1', 'score': 0.9544893503189087},\n",
       " {'label': 'LABEL_0', 'score': 0.9959618449211121},\n",
       " {'label': 'LABEL_0', 'score': 0.9893727898597717},\n",
       " {'label': 'LABEL_0', 'score': 0.970529317855835},\n",
       " {'label': 'LABEL_1', 'score': 0.9841547012329102},\n",
       " {'label': 'LABEL_0', 'score': 0.96929931640625},\n",
       " {'label': 'LABEL_0', 'score': 0.8777941465377808},\n",
       " {'label': 'LABEL_0', 'score': 0.9888051748275757},\n",
       " {'label': 'LABEL_0', 'score': 0.9791433811187744}]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = predictor.predict({\"inputs\":[tokenizer.decode(test_dataset[i]['input_ids'], skip_special_tokens=True) for i in sample_mask]})\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613bb050-6d76-47e5-a94a-584b295afd58",
   "metadata": {},
   "source": [
    "## Convert model outputs to informative strings and compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ed5fc354-d6e7-455a-838b-b8eda1389aab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground Truth: positive | Prediction: positive -- Correct: True\n",
      "Ground Truth: positive | Prediction: positive -- Correct: True\n",
      "Ground Truth: negative | Prediction: negative -- Correct: True\n",
      "Ground Truth: negative | Prediction: negative -- Correct: True\n",
      "Ground Truth: negative | Prediction: negative -- Correct: True\n",
      "Ground Truth: positive | Prediction: positive -- Correct: True\n",
      "Ground Truth: negative | Prediction: negative -- Correct: True\n",
      "Ground Truth: negative | Prediction: negative -- Correct: True\n",
      "Ground Truth: negative | Prediction: negative -- Correct: True\n",
      "Ground Truth: negative | Prediction: negative -- Correct: True\n"
     ]
    }
   ],
   "source": [
    "for pred, truth in zip(results, ground_truth):\n",
    "    print(f\"Ground Truth: {id2label[f'LABEL_{truth}']} | Prediction: {id2label[pred['label']]} -- Correct: {id2label[f'LABEL_{truth}'] == id2label[pred['label']]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14eb54f4-9d78-4d17-bf2d-c98712496e59",
   "metadata": {},
   "source": [
    "## Delete the endpoint if it is not going to be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "34b0ae07-dea3-47f2-9915-a625e3e490f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 1.8 Python 3.6 CPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/1.8.1-cpu-py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
