{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and run a hyperparameter tuning job with the SageMaker SDK and HuggingFace container\n",
    "1. Load data to S3 for training.\n",
    "2. Configure SageMaker HuggingFace estimator.\n",
    "3. Select hyperparameters to search.\n",
    "4. Configure hyperparameter sweep with SageMaker Tuner.\n",
    "5. Evaluate results.\n",
    "6. Use best model for inference and deploy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pip installs\n",
    "sagemaker, transformers, and datasets - versions can vary depending on needs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ! pip install \"sagemaker>=2.48.0\" \"transformers==4.12.3\" \"datasets[s3]==1.18.3\" --upgrade\n",
    "# ! pip install aiobotocore==2.3.4\n",
    "# ! pip install s3fs --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "import sagemaker.huggingface\n",
    "from sagemaker.tuner import (\n",
    "    IntegerParameter,\n",
    "    CategoricalParameter,\n",
    "    ContinuousParameter,\n",
    "    HyperparameterTuner\n",
    ")\n",
    "\n",
    "from sagemaker.huggingface import HuggingFace\n",
    "\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "import s3fs\n",
    "\n",
    "from utils import summarize_hpo_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "session = sagemaker.Session()\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "role_name = role.split('/')[-1]\n",
    "\n",
    "sagemaker_session_bucket = session.default_bucket()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker role arn: arn:aws:iam::264639154954:role/aaca-ani-cogsci-sagemaker-studio-role\n",
      "sagemaker bucket: sagemaker-us-east-1-264639154954\n",
      "sagemaker session region: us-east-1\n"
     ]
    }
   ],
   "source": [
    "session = sagemaker.Session(default_bucket=sagemaker_session_bucket)\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {session.default_bucket()}\")\n",
    "print(f\"sagemaker session region: {session.boto_region_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download data from Datasets library and store in S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_name = \"tweet_eval\"\n",
    "dataset_subgroup = \"sentiment\"\n",
    "\n",
    "s3_prefix = \"samples/datasets/tweet_eval\"\n",
    "\n",
    "tokenizer_name = \"distilbert-base-uncased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset tweet_eval (/root/.cache/huggingface/datasets/tweet_eval/sentiment/1.1.0/12aee5282b8784f3e95459466db4cdf45c6bf49719c25cdb0743d71ed0410343)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50cfc5897e8b4b46b680ebb1e42299ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset tweet_eval (/root/.cache/huggingface/datasets/tweet_eval/sentiment/1.1.0/12aee5282b8784f3e95459466db4cdf45c6bf49719c25cdb0743d71ed0410343)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6fd1b3f75df45ba9f3e4674a154921b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset(dataset_name, dataset_subgroup, ignore_verifications=True)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "\n",
    "#tokenizer helper function\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch['text'], padding='max_length', truncation=True)\n",
    "\n",
    "# load dataset\n",
    "train_dataset, test_dataset = load_dataset(dataset_name, dataset_subgroup, split=['train', 'test'])\n",
    "test_dataset = test_dataset.shuffle().select(range(10000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/tweet_eval/sentiment/1.1.0/12aee5282b8784f3e95459466db4cdf45c6bf49719c25cdb0743d71ed0410343/cache-a36b975b9ca349ef.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee58e67e757b408aa411f4430bdf21a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset = train_dataset.map(tokenize, batched=True, batch_size=len(train_dataset))\n",
    "test_dataset  = test_dataset.map(tokenize, batched=True, batch_size=len(test_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert to tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.rename_column(\"label\", \"labels\")\n",
    "train_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "test_dataset = test_dataset.rename_column(\"label\", \"labels\")\n",
    "test_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload data to S3 using the 'save_to_disk' Datasets method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Upload data to S3 using the 'save_to_disk' Datasets method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_path: s3://sagemaker-us-east-1-264639154954/samples/datasets/tweet_eval/train\n",
      "test_path: s3://sagemaker-us-east-1-264639154954/samples/datasets/tweet_eval/test\n"
     ]
    }
   ],
   "source": [
    "s3 = s3fs.S3FileSystem()\n",
    "\n",
    "training_input_path = f\"s3://{session.default_bucket()}/{s3_prefix}/train\"\n",
    "train_dataset.save_to_disk(training_input_path, fs=s3)\n",
    "\n",
    "test_input_path = f\"s3://{session.default_bucket()}/{s3_prefix}/test\"\n",
    "test_dataset.save_to_disk(test_input_path, fs=s3)\n",
    "\n",
    "print(f\"train_path: {training_input_path}\")\n",
    "print(f\"test_path: {test_input_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set hyperparamter values that are passed to the estimtor, but we are not seeking to tune."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hyperparameters = {\"epochs\": 2,\n",
    "                   \"train_batch_size\": 16,\n",
    "                   \"model_name\": \"distilbert-base-uncased\",\n",
    "                   \"num_labels\": len(set(dataset['train']['label'])),\n",
    "                   \"metic\": \"f1\",\n",
    "                  }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure HuggingFace estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tags very useful in multi-user accounts for tracking key information\n",
    "TAGS = [{\"Key\": \"Owner\", \"Value\": \"ccooney@aflac.com\"},\n",
    "        {\"Key\": \"Environment\", \"Value\": \"Dev\"}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SageMaker has a specific estimator for use with HuggingFace (https://sagemaker.readthedocs.io/en/stable/frameworks/huggingface/sagemaker.huggingface.html)\n",
    "\n",
    "It requires a python script to be passed (this is the main training script for your model). Other important parameters include instance type and package versioning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "huggingface_estimator = HuggingFace(entry_point='training_script.py',\n",
    "                                    source_dir='./scripts',\n",
    "                                    sagemaker_session=session,\n",
    "                                    instance_type='ml.p3.2xlarge',\n",
    "                                    instance_count=1,\n",
    "                                    role=role,\n",
    "                                    transformers_version='4.12',\n",
    "                                    py_version='py38',\n",
    "                                    pytorch_version='1.9',\n",
    "                                    hyperparameters=hyperparameters,\n",
    "                                    base_job_name='hpo-HF')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize hyperparameter ranges and the metric for evaluating model performance.\n",
    "\n",
    "There are many hyperparameters that can be tuned the selection with largely be dependent on the type of model you are working with.\n",
    "\n",
    "The SageMaker SDK enables setting of hyperparameter ranges through the ContinuousParameter, IntegerParameter, and CategoricalParameter methods.\n",
    "\n",
    "Look at the arguments being parsed in training_script.py to see some other hyperparameters that could be tuned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hyperparameter_ranges = {\"learning_rate\": ContinuousParameter(0.0001, 0.1),\n",
    "                         \"warmup_steps\": IntegerParameter(100, 500),\n",
    "                         \"optimizer\": CategoricalParameter([\"AdamW\", \"Adafactor\"]),\n",
    "                         \"weight_decay\": ContinuousParameter(0.00, 0.001)}\n",
    "\n",
    "objective_metric = \"loss\"\n",
    "objective_type = \"Minimize\"\n",
    "metric_definitions = [{\"Name\": \"loss\", \"Regex\": \"loss = ([0-9\\\\.]+)\"}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure tuner\n",
    "Pass the estimator, as well as the objective metric and the hyperparameter ranges we want to tune.\n",
    "It is also possible to define the optimization strategy as 'Bayesian' | 'Random' | 'Hyperband' | 'Grid' (https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_HyperParameterTuningJobConfig.html) - Here, we go with the default Bayesian approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tuner = HyperparameterTuner(huggingface_estimator,\n",
    "                            objective_metric,\n",
    "                            hyperparameter_ranges,\n",
    "                            metric_definitions,\n",
    "                            max_jobs=3,\n",
    "                            max_parallel_jobs=2,\n",
    "                            objective_type=objective_type,\n",
    "                            tags=TAGS,\n",
    "                            base_tuning_job_name=\"hpo-HF\",)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then call the fit method in the same way you would with a normal SageMaker estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................!\n"
     ]
    }
   ],
   "source": [
    "tuner.fit(inputs={\"train\": training_input_path, \"test\": test_input_path})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tuner.describe() prints details of the tuning job we created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'HyperParameterTuningJobName': 'hpo-HF-230208-1023',\n",
       " 'HyperParameterTuningJobArn': 'arn:aws:sagemaker:us-east-1:264639154954:hyper-parameter-tuning-job/hpo-hf-230208-1023',\n",
       " 'HyperParameterTuningJobConfig': {'Strategy': 'Bayesian',\n",
       "  'HyperParameterTuningJobObjective': {'Type': 'Minimize',\n",
       "   'MetricName': 'loss'},\n",
       "  'ResourceLimits': {'MaxNumberOfTrainingJobs': 3,\n",
       "   'MaxParallelTrainingJobs': 2},\n",
       "  'ParameterRanges': {'IntegerParameterRanges': [{'Name': 'warmup_steps',\n",
       "     'MinValue': '100',\n",
       "     'MaxValue': '500',\n",
       "     'ScalingType': 'Auto'}],\n",
       "   'ContinuousParameterRanges': [{'Name': 'learning_rate',\n",
       "     'MinValue': '0.0001',\n",
       "     'MaxValue': '0.1',\n",
       "     'ScalingType': 'Auto'},\n",
       "    {'Name': 'weight_decay',\n",
       "     'MinValue': '0.0',\n",
       "     'MaxValue': '0.001',\n",
       "     'ScalingType': 'Auto'}],\n",
       "   'CategoricalParameterRanges': [{'Name': 'optimizer',\n",
       "     'Values': ['\"AdamW\"', '\"Adafactor\"']}]},\n",
       "  'TrainingJobEarlyStoppingType': 'Off'},\n",
       " 'TrainingJobDefinition': {'StaticHyperParameters': {'_tuning_objective_metric': 'loss',\n",
       "   'epochs': '2',\n",
       "   'metic': '\"f1\"',\n",
       "   'model_name': '\"distilbert-base-uncased\"',\n",
       "   'num_labels': '3',\n",
       "   'sagemaker_container_log_level': '20',\n",
       "   'sagemaker_estimator_class_name': '\"HuggingFace\"',\n",
       "   'sagemaker_estimator_module': '\"sagemaker.huggingface.estimator\"',\n",
       "   'sagemaker_job_name': '\"hpo-HF-2023-02-08-10-23-38-242\"',\n",
       "   'sagemaker_program': '\"training_script.py\"',\n",
       "   'sagemaker_region': '\"us-east-1\"',\n",
       "   'sagemaker_submit_directory': '\"s3://sagemaker-us-east-1-264639154954/hpo-HF-2023-02-08-10-23-38-242/source/sourcedir.tar.gz\"',\n",
       "   'train_batch_size': '16'},\n",
       "  'AlgorithmSpecification': {'TrainingImage': '763104351884.dkr.ecr.us-east-1.amazonaws.com/huggingface-pytorch-training:1.9-transformers4.12-gpu-py38-cu111-ubuntu20.04',\n",
       "   'TrainingInputMode': 'File',\n",
       "   'MetricDefinitions': [{'Name': 'loss', 'Regex': 'loss = ([0-9\\\\.]+)'},\n",
       "    {'Name': 'ObjectiveMetric', 'Regex': 'loss = ([0-9\\\\.]+)'}]},\n",
       "  'RoleArn': 'arn:aws:iam::264639154954:role/aaca-ani-cogsci-sagemaker-studio-role',\n",
       "  'InputDataConfig': [{'ChannelName': 'train',\n",
       "    'DataSource': {'S3DataSource': {'S3DataType': 'S3Prefix',\n",
       "      'S3Uri': 's3://sagemaker-us-east-1-264639154954/samples/datasets/tweet_eval/train',\n",
       "      'S3DataDistributionType': 'FullyReplicated'}}},\n",
       "   {'ChannelName': 'test',\n",
       "    'DataSource': {'S3DataSource': {'S3DataType': 'S3Prefix',\n",
       "      'S3Uri': 's3://sagemaker-us-east-1-264639154954/samples/datasets/tweet_eval/test',\n",
       "      'S3DataDistributionType': 'FullyReplicated'}}}],\n",
       "  'OutputDataConfig': {'S3OutputPath': 's3://sagemaker-us-east-1-264639154954/'},\n",
       "  'ResourceConfig': {'InstanceType': 'ml.p3.2xlarge',\n",
       "   'InstanceCount': 1,\n",
       "   'VolumeSizeInGB': 30},\n",
       "  'StoppingCondition': {'MaxRuntimeInSeconds': 86400},\n",
       "  'EnableNetworkIsolation': False,\n",
       "  'EnableInterContainerTrafficEncryption': False,\n",
       "  'EnableManagedSpotTraining': False},\n",
       " 'HyperParameterTuningJobStatus': 'Completed',\n",
       " 'CreationTime': datetime.datetime(2023, 2, 8, 10, 23, 38, 605000, tzinfo=tzlocal()),\n",
       " 'HyperParameterTuningEndTime': datetime.datetime(2023, 2, 8, 11, 28, 22, 576000, tzinfo=tzlocal()),\n",
       " 'LastModifiedTime': datetime.datetime(2023, 2, 8, 11, 28, 22, 576000, tzinfo=tzlocal()),\n",
       " 'TrainingJobStatusCounters': {'Completed': 3,\n",
       "  'InProgress': 0,\n",
       "  'RetryableError': 0,\n",
       "  'NonRetryableError': 0,\n",
       "  'Stopped': 0},\n",
       " 'ObjectiveStatusCounters': {'Succeeded': 3, 'Pending': 0, 'Failed': 0},\n",
       " 'BestTrainingJob': {'TrainingJobName': 'hpo-HF-230208-1023-003-f10bbaed',\n",
       "  'TrainingJobArn': 'arn:aws:sagemaker:us-east-1:264639154954:training-job/hpo-HF-230208-1023-003-f10bbaed',\n",
       "  'CreationTime': datetime.datetime(2023, 2, 8, 10, 58, 55, tzinfo=tzlocal()),\n",
       "  'TrainingStartTime': datetime.datetime(2023, 2, 8, 10, 58, 59, tzinfo=tzlocal()),\n",
       "  'TrainingEndTime': datetime.datetime(2023, 2, 8, 11, 26, 7, tzinfo=tzlocal()),\n",
       "  'TrainingJobStatus': 'Completed',\n",
       "  'TunedHyperParameters': {'learning_rate': '0.00017545073264835974',\n",
       "   'optimizer': '\"Adafactor\"',\n",
       "   'warmup_steps': '192',\n",
       "   'weight_decay': '0.00011148831909139079'},\n",
       "  'FinalHyperParameterTuningJobObjectiveMetric': {'MetricName': 'loss',\n",
       "   'Value': 0.007822966203093529},\n",
       "  'ObjectiveStatus': 'Succeeded'},\n",
       " 'ResponseMetadata': {'RequestId': 'f711d107-c9bd-4d42-b5aa-3165571709aa',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'f711d107-c9bd-4d42-b5aa-3165571709aa',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '3806',\n",
       "   'date': 'Wed, 08 Feb 2023 11:47:04 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuner.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the results as a pandas DataFrame for a comparison of all hyperparameter combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>warmup_steps</th>\n",
       "      <th>weight_decay</th>\n",
       "      <th>TrainingJobName</th>\n",
       "      <th>TrainingJobStatus</th>\n",
       "      <th>FinalObjectiveValue</th>\n",
       "      <th>TrainingStartTime</th>\n",
       "      <th>TrainingEndTime</th>\n",
       "      <th>TrainingElapsedTimeSeconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000175</td>\n",
       "      <td>\"Adafactor\"</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>hpo-HF-230208-1023-003-f10bbaed</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.007823</td>\n",
       "      <td>2023-02-08 10:58:59+00:00</td>\n",
       "      <td>2023-02-08 11:26:07+00:00</td>\n",
       "      <td>1628.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.006286</td>\n",
       "      <td>\"AdamW\"</td>\n",
       "      <td>240.0</td>\n",
       "      <td>0.000910</td>\n",
       "      <td>hpo-HF-230208-1023-002-867283a9</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.011643</td>\n",
       "      <td>2023-02-08 10:25:34+00:00</td>\n",
       "      <td>2023-02-08 10:57:15+00:00</td>\n",
       "      <td>1901.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.004381</td>\n",
       "      <td>\"Adafactor\"</td>\n",
       "      <td>358.0</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>hpo-HF-230208-1023-001-f7897507</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.011697</td>\n",
       "      <td>2023-02-08 10:25:36+00:00</td>\n",
       "      <td>2023-02-08 10:57:41+00:00</td>\n",
       "      <td>1925.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   learning_rate    optimizer  warmup_steps  weight_decay  \\\n",
       "0       0.000175  \"Adafactor\"         192.0      0.000111   \n",
       "1       0.006286      \"AdamW\"         240.0      0.000910   \n",
       "2       0.004381  \"Adafactor\"         358.0      0.000072   \n",
       "\n",
       "                   TrainingJobName TrainingJobStatus  FinalObjectiveValue  \\\n",
       "0  hpo-HF-230208-1023-003-f10bbaed         Completed             0.007823   \n",
       "1  hpo-HF-230208-1023-002-867283a9         Completed             0.011643   \n",
       "2  hpo-HF-230208-1023-001-f7897507         Completed             0.011697   \n",
       "\n",
       "          TrainingStartTime           TrainingEndTime  \\\n",
       "0 2023-02-08 10:58:59+00:00 2023-02-08 11:26:07+00:00   \n",
       "1 2023-02-08 10:25:34+00:00 2023-02-08 10:57:15+00:00   \n",
       "2 2023-02-08 10:25:36+00:00 2023-02-08 10:57:41+00:00   \n",
       "\n",
       "   TrainingElapsedTimeSeconds  \n",
       "0                      1628.0  \n",
       "1                      1901.0  \n",
       "2                      1925.0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = tuner.analytics().dataframe()\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>warmup_steps</th>\n",
       "      <th>weight_decay</th>\n",
       "      <th>TrainingJobName</th>\n",
       "      <th>TrainingJobStatus</th>\n",
       "      <th>FinalObjectiveValue</th>\n",
       "      <th>TrainingStartTime</th>\n",
       "      <th>TrainingEndTime</th>\n",
       "      <th>TrainingElapsedTimeSeconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000175</td>\n",
       "      <td>\"Adafactor\"</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>hpo-HF-230208-1023-003-f10bbaed</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.007823</td>\n",
       "      <td>2023-02-08 10:58:59+00:00</td>\n",
       "      <td>2023-02-08 11:26:07+00:00</td>\n",
       "      <td>1628.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.006286</td>\n",
       "      <td>\"AdamW\"</td>\n",
       "      <td>240.0</td>\n",
       "      <td>0.000910</td>\n",
       "      <td>hpo-HF-230208-1023-002-867283a9</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.011643</td>\n",
       "      <td>2023-02-08 10:25:34+00:00</td>\n",
       "      <td>2023-02-08 10:57:15+00:00</td>\n",
       "      <td>1901.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.004381</td>\n",
       "      <td>\"Adafactor\"</td>\n",
       "      <td>358.0</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>hpo-HF-230208-1023-001-f7897507</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.011697</td>\n",
       "      <td>2023-02-08 10:25:36+00:00</td>\n",
       "      <td>2023-02-08 10:57:41+00:00</td>\n",
       "      <td>1925.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   learning_rate    optimizer  warmup_steps  weight_decay  \\\n",
       "0       0.000175  \"Adafactor\"         192.0      0.000111   \n",
       "1       0.006286      \"AdamW\"         240.0      0.000910   \n",
       "2       0.004381  \"Adafactor\"         358.0      0.000072   \n",
       "\n",
       "                   TrainingJobName TrainingJobStatus  FinalObjectiveValue  \\\n",
       "0  hpo-HF-230208-1023-003-f10bbaed         Completed             0.007823   \n",
       "1  hpo-HF-230208-1023-002-867283a9         Completed             0.011643   \n",
       "2  hpo-HF-230208-1023-001-f7897507         Completed             0.011697   \n",
       "\n",
       "          TrainingStartTime           TrainingEndTime  \\\n",
       "0 2023-02-08 10:58:59+00:00 2023-02-08 11:26:07+00:00   \n",
       "1 2023-02-08 10:25:34+00:00 2023-02-08 10:57:15+00:00   \n",
       "2 2023-02-08 10:25:36+00:00 2023-02-08 10:57:41+00:00   \n",
       "\n",
       "   TrainingElapsedTimeSeconds  \n",
       "0                      1628.0  \n",
       "1                      1901.0  \n",
       "2                      1925.0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.sort_values('FinalObjectiveValue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print best results for ease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score: 0.007822966203093529\n",
      "best params: {'learning_rate': '0.00017545073264835974', 'optimizer': '\"Adafactor\"', 'warmup_steps': '192', 'weight_decay': '0.00011148831909139079'}\n",
      "best job-name: hpo-HF-230208-1023-003-f10bbaed\n"
     ]
    }
   ],
   "source": [
    "summarize_hpo_results(tuner.latest_tuning_job.job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hpo-HF-230208-1023-003-f10bbaed'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuner.best_training_job()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the best tuned model for deploying and making predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2023-02-08 11:26:09 Starting - Found matching resource for reuse\n",
      "2023-02-08 11:26:09 Downloading - Downloading input data\n",
      "2023-02-08 11:26:09 Training - Training image download completed. Training in progress.\n",
      "2023-02-08 11:26:09 Uploading - Uploading generated training model\n",
      "2023-02-08 11:26:09 Completed - Resource released due to keep alive period expiry\n"
     ]
    }
   ],
   "source": [
    "best_estimator = tuner.best_estimator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deploy the model to a SageMaker Endpoint, choosing an instance type for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------!"
     ]
    }
   ],
   "source": [
    "predictor = best_estimator.deploy(1, \"ml.g4dn.xlarge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use your deployed model to make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_2', 'score': 0.9897397756576538}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = predictor.predict({\"inputs\": \"Best thing ever!\"})\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpret the general 'LABEL_0' as positive or negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: positive\n"
     ]
    }
   ],
   "source": [
    "classes = [\"negative\", \"neutral\", \"positive\"]\n",
    "id2label = {f\"LABEL_{v}\": k for v, k in enumerate(classes)}\n",
    "\n",
    "print(f\"Result: {id2label[result[0]['label']]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete endpoint when complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.large",
  "interpreter": {
   "hash": "556bd3c69953d81d367d63bac13dd17e253d3fab989eb80647a7980e8f2979cc"
  },
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 1.8 Python 3.6 CPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/1.8.1-cpu-py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
